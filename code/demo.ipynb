{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "95yZyb6qr_0S",
        "gAy1cbNRsC94",
        "9LVI7b93AbUB",
        "M47qzWFHsJuC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68bb4ddda99f49b5ba922a1dc03c249b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cd4f09d78a64896990f822dfb5c8ff0",
              "IPY_MODEL_4aad9155ffb34810a9abe3046c74dae2",
              "IPY_MODEL_bc4a4ff1298642d29e2fa5b9c1cd4e2f"
            ],
            "layout": "IPY_MODEL_ffdf2781ca4244bdb7240b4b408e3a3f"
          }
        },
        "5cd4f09d78a64896990f822dfb5c8ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63b357d60d73409f996033f618c710ca",
            "placeholder": "​",
            "style": "IPY_MODEL_9ca34afbc6ef4596b149877a5c38d192",
            "value": "Epoch 0:   0%"
          }
        },
        "4aad9155ffb34810a9abe3046c74dae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bdce0fabc3f40349ec6e4b5faf18b8b",
            "max": 67,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e47039e7d5a460085fcdcb602167e00",
            "value": 0
          }
        },
        "bc4a4ff1298642d29e2fa5b9c1cd4e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c172c14511b4915b60bcfbe39a7967e",
            "placeholder": "​",
            "style": "IPY_MODEL_f2bc939f9ee94f00a8582899910eb8c5",
            "value": " 0/67 [00:00&lt;?, ?it/s]"
          }
        },
        "ffdf2781ca4244bdb7240b4b408e3a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "63b357d60d73409f996033f618c710ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca34afbc6ef4596b149877a5c38d192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bdce0fabc3f40349ec6e4b5faf18b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e47039e7d5a460085fcdcb602167e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c172c14511b4915b60bcfbe39a7967e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bc939f9ee94f00a8582899910eb8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc2a418a11e434baecd4674ebca8271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_632b836f5efe48c281f823b50c475163",
              "IPY_MODEL_21c749a6fa7346c69ba17088d729f850",
              "IPY_MODEL_e6d083ba837940139a9b8f1e266a9293"
            ],
            "layout": "IPY_MODEL_929565c543cd4f5e98d55d7d6ccbf805"
          }
        },
        "632b836f5efe48c281f823b50c475163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efdda1605aba41a1954c97ad5ccde981",
            "placeholder": "​",
            "style": "IPY_MODEL_34672816365c4a49a2c0dbfe6bb6db58",
            "value": "Epoch 0:   0%"
          }
        },
        "21c749a6fa7346c69ba17088d729f850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c45243f54549a3916de80e3182e577",
            "max": 67,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a4ed993a61849d7ade71772405b4773",
            "value": 0
          }
        },
        "e6d083ba837940139a9b8f1e266a9293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04edbcce6ac640889efb18beba54aabe",
            "placeholder": "​",
            "style": "IPY_MODEL_303ee53ed8004b46afabe289b340e0f3",
            "value": " 0/67 [11:46&lt;?, ?it/s]"
          }
        },
        "929565c543cd4f5e98d55d7d6ccbf805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "efdda1605aba41a1954c97ad5ccde981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34672816365c4a49a2c0dbfe6bb6db58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45c45243f54549a3916de80e3182e577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4ed993a61849d7ade71772405b4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04edbcce6ac640889efb18beba54aabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303ee53ed8004b46afabe289b340e0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict -q\n",
        "!pip install torchode -q\n",
        "!pip install missingno -q\n",
        "!pip install pytorch_lightning -q"
      ],
      "metadata": {
        "id": "1VsBHaPWsIfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0258236e-f184-447a-9496-b431e363aef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import missingno as msno\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "lsVsQiAZsxNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Код утилит"
      ],
      "metadata": {
        "id": "95yZyb6qr_0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdqrZMLNqjA0"
      },
      "outputs": [],
      "source": [
        "\"\"\"Batch-element-wise masking utilities.\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "def maskmax(t: Tensor, m: Tensor, dim: int, **kwargs):\n",
        "    \"\"\"Get the max element along dim, ignoring elements not in mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "    >>> m = torch.tensor([[1, 1, 0], [1, 1, 0]]).bool()\n",
        "    >>> maskmax(t, m, 1) # tensor([2., 5.])\n",
        "\n",
        "    \"\"\"\n",
        "    return torch.amax(torch.where(m, t, -torch.inf), dim=dim, **kwargs)\n",
        "\n",
        "\n",
        "def maskmin(t: Tensor, m: Tensor, dim: int, **kwargs):\n",
        "    \"\"\"Get the min element along dim, ignoring elements not in mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> t = torch.tensor([[3, 2, 1], [6, 5, 4]])\n",
        "    >>> m = torch.tensor([[1, 1, 0], [1, 1, 0]]).bool()\n",
        "    >>> maskmin(t, m, 1) # tensor([2., 5.])\n",
        "\n",
        "    \"\"\"\n",
        "    return torch.amin(torch.where(m, t, +torch.inf), dim=dim, **kwargs)\n",
        "\n",
        "\n",
        "def maskmean(t: Tensor, m: Tensor, dim: int, **kwargs):\n",
        "    \"\"\"Get the mean along dim, ignoring elements not in mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> t = torch.tensor([[1, 1, 9], [2, 2, 9]])\n",
        "    >>> m = torch.tensor([[1, 1, 0], [1, 1, 0]]).bool()\n",
        "    >>> maskmean(t, m, 1) # tensor([1., 2.])\n",
        "\n",
        "    \"\"\"\n",
        "    return torch.nanmean(torch.where(m, t, torch.nan), dim=dim, **kwargs)\n",
        "\n",
        "\n",
        "def masklast(t: Tensor, m: Tensor, dim: int, *, keepdim: bool = False):\n",
        "    \"\"\"Get the last element along dim, ignoring elements not in mask.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> t = torch.tensor([[2, 1, 3],\n",
        "                          [4, 1, 6]])\n",
        "    >>> m = torch.tensor([[1, 1, 1],\n",
        "                          [1, 1, 0]]).bool()\n",
        "    >>> masklast(t, m, 1) # tensor([3., 1.])\n",
        "\n",
        "    \"\"\"\n",
        "    indices = (torch.sum(m, dim) - 1).int()\n",
        "    idx = [torch.arange(0, size) for size in indices.shape]\n",
        "    idx.insert(dim, indices)\n",
        "    t = t[idx]\n",
        "    if keepdim:\n",
        "        t = t.unsqueeze(dim)\n",
        "\n",
        "    return t\n",
        "\n",
        "\n",
        "def complex_log(float_input, eps=1e-6):\n",
        "    \"\"\"Compute the complex logarithm.\n",
        "\n",
        "    Used in associative_scan.\n",
        "    \"\"\"\n",
        "    eps = float_input.new_tensor(eps)\n",
        "    real = float_input.abs().maximum(eps).log()\n",
        "    imag = (float_input < 0).to(float_input.dtype) * torch.pi\n",
        "    return torch.complex(real, imag)\n",
        "\n",
        "\n",
        "def associative_scan(values: torch.Tensor, coeffs: torch.Tensor, dim: int):\n",
        "    \"\"\"Calculate cumsum with resets.\n",
        "\n",
        "    Source: https://github.com/pytorch/pytorch/issues/53095#issuecomment-2102409471.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> input = torch.tensor([1, 2, 3, 4, 5])\n",
        "    >>> inverted_reset_mask = torch.tensor([0, 1, 1, 0, 1])\n",
        "    >>> output = associative_scan(input, inverted_reset_mask, dim=0)\n",
        "    >>> print(output)\n",
        "    tensor([1.0000, 3.0000, 6.0000, 4.0000, 9.0000])\n",
        "\n",
        "    \"\"\"\n",
        "    log_values = complex_log(values.float())\n",
        "    log_coeffs = complex_log(coeffs.float())\n",
        "    a_star = torch.cumsum(log_coeffs, dim=dim)\n",
        "    log_x0_plus_b_star = torch.logcumsumexp(log_values - a_star, dim=dim)\n",
        "    log_x = a_star + log_x0_plus_b_star\n",
        "    return torch.exp(log_x).real\n",
        "\n",
        "\n",
        "def roll_padding(t: Tensor, m: Tensor):\n",
        "    \"\"\"Roll padding specified by `m` to end over the last dimension of mask `m`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        tuple of new tensor and new padding mask\n",
        "\n",
        "    \"\"\"\n",
        "    nkeep = m.sum(-1, keepdim=True)\n",
        "    firstel_mask = nkeep > torch.arange(m.size(-1), device=m.device)\n",
        "    tnew = torch.zeros_like(t)\n",
        "    tnew[firstel_mask] = t[m]\n",
        "    return tnew, firstel_mask\n",
        "\n",
        "\n",
        "def sum_simultaneous(x: Tensor, t: Tensor, m):\n",
        "    \"\"\"Sum simultaneous events.\"\"\"\n",
        "    simultaneous_mask = torch.zeros_like(t, dtype=torch.bool)\n",
        "    simultaneous_mask[:, 1:] = t[:, 1:] == t[:, :-1]\n",
        "    x = associative_scan(x, simultaneous_mask.unsqueeze(-1), 1)\n",
        "    keep_mask = torch.ones_like(simultaneous_mask)\n",
        "    keep_mask[:, :-1] = ~simultaneous_mask[:, 1:]\n",
        "    keep_mask = keep_mask & m\n",
        "    x, mask = roll_padding(x, keep_mask)\n",
        "    t, mask = roll_padding(t, keep_mask)\n",
        "    return x, t, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Код TPP ODE"
      ],
      "metadata": {
        "id": "gAy1cbNRsC94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch ODE example\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchode as to\n",
        "\n",
        "torch.random.manual_seed(180819023)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_features, n_hidden):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(n_features, n_hidden),\n",
        "            nn.Softplus(),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.Softplus(),\n",
        "            nn.Linear(n_hidden, n_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, t, y):\n",
        "        return self.layers(y)\n",
        "\n",
        "n_features = 5\n",
        "model = Model(n_features=n_features, n_hidden=32)\n",
        "\n",
        "\n",
        "dev = torch.device(\"cpu\")\n",
        "term = to.ODETerm(model)\n",
        "step_method = to.Dopri5(term=term)\n",
        "step_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\n",
        "\n",
        "adjoint = to.AutoDiffAdjoint(step_method, step_size_controller).to(dev)\n",
        "adjoint_jit = torch.jit.script(adjoint)\n",
        "\n",
        "batch_size = 3\n",
        "t_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\n",
        "problem = to.InitialValueProblem(y0=torch.zeros((batch_size, n_features)).to(dev), t_eval=t_eval.to(dev))\n",
        "\n",
        "\n",
        "sol = adjoint.solve(problem)\n",
        "sol_jit = adjoint_jit.solve(problem)\n",
        "\n",
        "print(sol.stats)\n",
        "print(sol_jit.stats)\n",
        "print(\"Max absolute difference\", float((sol.ys - sol_jit.ys).abs().max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9r6xJcyiZZp",
        "outputId": "3207468b-b0fc-478c-b639-5fdc76ba0b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_f_evals': tensor([38, 38, 38]), 'n_steps': tensor([6, 6, 6]), 'n_accepted': tensor([6, 6, 6]), 'n_initialized': tensor([10, 10, 10])}\n",
            "{'n_f_evals': tensor([38, 38, 38]), 'n_steps': tensor([6, 6, 6]), 'n_accepted': tensor([6, 6, 6]), 'n_initialized': tensor([10, 10, 10])}\n",
            "Max absolute difference 2.205371856689453e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol.ts.shape # [batch_size, T]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyDgrxYuinwl",
        "outputId": "5b469a52-d441-4af0-edf1-74b7519b727b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol.ys.shape # [batch_size, T, hidden_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXUs2AjXixVC",
        "outputId": "704d526a-6ac1-4182-ebd1-6725ee9b9eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBackbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "class CatEmbedding(nn.Module):\n",
        "    def __init__(self, n_classes: int, embedding_dim: int = 32):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(n_classes, embedding_dim)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # batch: [batch_size, T] <--- int values of classes ids\n",
        "\n",
        "        assert len(batch.shape) == 2\n",
        "\n",
        "        return self.embedding(batch) # [batch_size, T, embedding_dim]\n",
        "\n",
        "n_classes = 3\n",
        "T = 100\n",
        "emb_dim = 8\n",
        "batch_size = 2\n",
        "cat_emb = CatEmbedding(n_classes, emb_dim)\n",
        "res = cat_emb(torch.randint(low=0, high=n_classes, size=(batch_size, T)))\n",
        "print(res)\n",
        "assert res.shape == (batch_size, T, emb_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY7nyaR2E2YV",
        "outputId": "3c861af6-92be-4175-8d3c-fd4c5c6edca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.1834,  0.5987, -0.0172,  ...,  0.9349,  0.3069,  0.3437],\n",
            "         [ 1.2050, -2.5556,  0.7688,  ..., -0.1799,  0.1548,  1.4784],\n",
            "         [ 0.2382,  0.4838, -0.4177,  ..., -0.6549,  0.2083,  0.4805],\n",
            "         ...,\n",
            "         [ 0.2382,  0.4838, -0.4177,  ..., -0.6549,  0.2083,  0.4805],\n",
            "         [ 1.2050, -2.5556,  0.7688,  ..., -0.1799,  0.1548,  1.4784],\n",
            "         [ 0.2382,  0.4838, -0.4177,  ..., -0.6549,  0.2083,  0.4805]],\n",
            "\n",
            "        [[ 1.2050, -2.5556,  0.7688,  ..., -0.1799,  0.1548,  1.4784],\n",
            "         [ 1.1834,  0.5987, -0.0172,  ...,  0.9349,  0.3069,  0.3437],\n",
            "         [ 1.2050, -2.5556,  0.7688,  ..., -0.1799,  0.1548,  1.4784],\n",
            "         ...,\n",
            "         [ 1.1834,  0.5987, -0.0172,  ...,  0.9349,  0.3069,  0.3437],\n",
            "         [ 0.2382,  0.4838, -0.4177,  ..., -0.6549,  0.2083,  0.4805],\n",
            "         [ 1.2050, -2.5556,  0.7688,  ..., -0.1799,  0.1548,  1.4784]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Оригинальный тензор формы (1, 3)\n",
        "tensor = torch.tensor([[1, 2, 3]])\n",
        "print(\"Оригинальная форма тензора:\", tensor.shape)\n",
        "\n",
        "# Расширение тензора до формы (4, 3)\n",
        "expanded_tensor = tensor.expand(4, 3)\n",
        "print(\"Расширенная форма тензора:\", expanded_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVhgy8a_a_DV",
        "outputId": "0a810784-1850-47e9-c3f0-62df4b5ab3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оригинальная форма тензора: torch.Size([1, 3])\n",
            "Расширенная форма тензора: torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expanded_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "squup74cbAYl",
        "outputId": "b12b674b-d737-40fc-d49d-9260428d5478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [1, 2, 3],\n",
              "        [1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "t_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\n",
        "t_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRr-mJDZhqPP",
        "outputId": "cff507a5-1e53-4a05-dbb4-72aae9977053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.3333, 0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667,\n",
              "         3.0000],\n",
              "        [0.0000, 0.3333, 0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667,\n",
              "         3.0000],\n",
              "        [0.0000, 0.3333, 0.6667, 1.0000, 1.3333, 1.6667, 2.0000, 2.3333, 2.6667,\n",
              "         3.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_eval.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1YEp32WhsaP",
        "outputId": "f8193441-c5fe-4232-8ffa-65d9b41b7999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensordict import TensorDict\n",
        "td = TensorDict({'a': torch.zeros(3, 4, 5)}, batch_size=[3, 4])\n",
        "# returns a TensorDict of batch size [3, 4, 1]:\n",
        "td_unsqueeze = td.unsqueeze(-1)\n",
        "# returns a TensorDict of batch size [12]\n",
        "td_view = td.view(-1)\n",
        "# returns a tensor of batch size [12, 4]\n",
        "a_view = td.view(-1).get(\"a\")"
      ],
      "metadata": {
        "id": "kbqKomdPhthn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "td_view.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcMC5-S1lDC1",
        "outputId": "91729c49-d041-4c5a-942e-05cc2be0ddc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorField_time(nn.Module):\n",
        "    def __init__(self, input_output_dim: int, hidden_dim: int = 32):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_output_dim = input_output_dim\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_output_dim + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(), # instead of ReLU\n",
        "            nn.Linear(hidden_dim, input_output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, times, y_s):\n",
        "        # times: [batch_size]\n",
        "        # y_s: [batch_size, input_dim]\n",
        "        # assert len(times.shape) == 1 and len(y_s.shape) == 2\n",
        "        # assert times.shape[0] == y_s.shape[0]\n",
        "        # assert y_s.shape[1] == self.input_output_dim\n",
        "\n",
        "        res = self.layers(torch.cat([y_s, times[..., None]], axis=-1)) # [batch_size, input_output_dim]\n",
        "        # print(f\"VF Result norm: {torch.sqrt((res ** 2).sum().sum()):.3f}\")\n",
        "        # print(f\"VF res: {res}\")\n",
        "        assert res.shape == y_s.shape\n",
        "\n",
        "        return res\n",
        "\n",
        "class VectorField(nn.Module):\n",
        "    def __init__(self, input_output_dim: int, hidden_dim: int = 32):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_output_dim = input_output_dim\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_output_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(), # instead of ReLU\n",
        "            nn.Linear(hidden_dim, input_output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, times, y_s):\n",
        "        # times: [batch_size]\n",
        "        # y_s: [batch_size, input_dim]\n",
        "        # assert len(times.shape) == 1 and len(y_s.shape) == 2\n",
        "        # assert times.shape[0] == y_s.shape[0]\n",
        "        # assert y_s.shape[1] == self.input_output_dim\n",
        "\n",
        "        res = self.layers(y_s) # [batch_size, input_output_dim]\n",
        "        assert res.shape == y_s.shape\n",
        "        print(f\"Res: {res}\")\n",
        "        # print(f\"VF res: {torch.norm(res)}\")\n",
        "        # print(f\"VF Result norm: {torch.sqrt((res ** 2).sum().sum()):.3f}\")\n",
        "        return res\n",
        "\n",
        "\n",
        "input_output_dim = 5\n",
        "batch_size = 8\n",
        "\n",
        "vf = VectorField(input_output_dim)\n",
        "\n",
        "times = torch.randn(size=(batch_size, ))\n",
        "y_s = torch.randn(size=(batch_size, input_output_dim))\n",
        "\n",
        "res = vf(times, y_s)\n",
        "print(res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxEtS3ymlKoi",
        "outputId": "642d9ada-c2eb-4876-e35c-cf27bb0314c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Res: tensor([[ 0.0967, -0.1183,  0.1953,  0.2361, -0.0527],\n",
            "        [-0.0622, -0.0880,  0.0976,  0.2218, -0.0546],\n",
            "        [ 0.1182,  0.0478,  0.3133,  0.2378, -0.0678],\n",
            "        [ 0.1800,  0.1763,  0.0573,  0.2568, -0.0333],\n",
            "        [ 0.2010,  0.0228,  0.1759,  0.2285,  0.1710],\n",
            "        [ 0.2070,  0.0522,  0.2412,  0.3855, -0.0352],\n",
            "        [ 0.1309, -0.0157,  0.1974,  0.2547, -0.0070],\n",
            "        [ 0.1089,  0.0159,  0.2136,  0.3113, -0.1271]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "torch.Size([8, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 5\n",
        "model = VectorField(n_features)\n",
        "# model = Model(n_features=n_features, n_hidden=32)\n",
        "\n",
        "\n",
        "dev = torch.device(\"cpu\")\n",
        "term = to.ODETerm(model)\n",
        "step_method = to.Dopri5(term=term)\n",
        "step_size_controller = to.IntegralController(atol=1e-6, rtol=1e-3, term=term)\n",
        "\n",
        "adjoint = to.AutoDiffAdjoint(step_method, step_size_controller).to(dev)\n",
        "# adjoint_jit = torch.jit.script(adjoint)\n",
        "\n",
        "batch_size = 3\n",
        "t_eval = torch.tile(torch.linspace(0.0, 3.0, 10), (batch_size, 1))\n",
        "problem = to.InitialValueProblem(y0=torch.zeros((batch_size, n_features)).to(dev), t_eval=t_eval.to(dev))\n",
        "\n",
        "\n",
        "sol = adjoint.solve(problem)\n",
        "# sol_jit = adjoint_jit.solve(problem)\n",
        "\n",
        "print(sol.stats)\n",
        "# print(sol_jit.stats)\n",
        "print(\"Max absolute difference\", float((sol.ys - sol_jit.ys).abs().max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO2Zovbz1WBG",
        "outputId": "f9e2b424-2ef4-4a97-add5-598365dac240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0794,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0948, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588],\n",
            "        [ 0.1325, -0.0949, -0.0795,  0.0468,  0.0588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.340\n",
            "VF res: tensor([[ 0.1325, -0.0951, -0.0797,  0.0469,  0.0589],\n",
            "        [ 0.1325, -0.0951, -0.0797,  0.0469,  0.0589],\n",
            "        [ 0.1325, -0.0951, -0.0797,  0.0469,  0.0589]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.341\n",
            "VF res: tensor([[ 0.1325, -0.0952, -0.0798,  0.0470,  0.0589],\n",
            "        [ 0.1325, -0.0952, -0.0798,  0.0470,  0.0589],\n",
            "        [ 0.1325, -0.0952, -0.0798,  0.0470,  0.0589]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.342\n",
            "VF res: tensor([[ 0.1326, -0.0957, -0.0802,  0.0473,  0.0590],\n",
            "        [ 0.1326, -0.0957, -0.0802,  0.0473,  0.0590],\n",
            "        [ 0.1326, -0.0957, -0.0802,  0.0473,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.342\n",
            "VF res: tensor([[ 0.1326, -0.0958, -0.0803,  0.0474,  0.0590],\n",
            "        [ 0.1326, -0.0958, -0.0803,  0.0474,  0.0590],\n",
            "        [ 0.1326, -0.0958, -0.0803,  0.0474,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.342\n",
            "VF res: tensor([[ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590],\n",
            "        [ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590],\n",
            "        [ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.342\n",
            "VF res: tensor([[ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590],\n",
            "        [ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590],\n",
            "        [ 0.1326, -0.0959, -0.0804,  0.0475,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.346\n",
            "VF res: tensor([[ 0.1329, -0.0979, -0.0821,  0.0487,  0.0594],\n",
            "        [ 0.1329, -0.0979, -0.0821,  0.0487,  0.0594],\n",
            "        [ 0.1329, -0.0979, -0.0821,  0.0487,  0.0594]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.348\n",
            "VF res: tensor([[ 0.1330, -0.0989, -0.0829,  0.0493,  0.0595],\n",
            "        [ 0.1330, -0.0989, -0.0829,  0.0493,  0.0595],\n",
            "        [ 0.1330, -0.0989, -0.0829,  0.0493,  0.0595]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.357\n",
            "VF res: tensor([[ 0.1336, -0.1038, -0.0862,  0.0534,  0.0592],\n",
            "        [ 0.1336, -0.1038, -0.0862,  0.0534,  0.0592],\n",
            "        [ 0.1336, -0.1038, -0.0862,  0.0534,  0.0592]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.358\n",
            "VF res: tensor([[ 0.1336, -0.1046, -0.0868,  0.0541,  0.0591],\n",
            "        [ 0.1336, -0.1046, -0.0868,  0.0541,  0.0591],\n",
            "        [ 0.1336, -0.1046, -0.0868,  0.0541,  0.0591]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.360\n",
            "VF res: tensor([[ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590],\n",
            "        [ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590],\n",
            "        [ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.360\n",
            "VF res: tensor([[ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590],\n",
            "        [ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590],\n",
            "        [ 0.1336, -0.1054, -0.0874,  0.0549,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.365\n",
            "VF res: tensor([[ 0.1335, -0.1086, -0.0900,  0.0585,  0.0583],\n",
            "        [ 0.1335, -0.1086, -0.0900,  0.0585,  0.0583],\n",
            "        [ 0.1335, -0.1086, -0.0900,  0.0585,  0.0583]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.368\n",
            "VF res: tensor([[ 0.1340, -0.1101, -0.0902,  0.0602,  0.0581],\n",
            "        [ 0.1340, -0.1101, -0.0902,  0.0602,  0.0581],\n",
            "        [ 0.1340, -0.1101, -0.0902,  0.0602,  0.0581]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.381\n",
            "VF res: tensor([[ 0.1359, -0.1170, -0.0899,  0.0693,  0.0590],\n",
            "        [ 0.1359, -0.1170, -0.0899,  0.0693,  0.0590],\n",
            "        [ 0.1359, -0.1170, -0.0899,  0.0693,  0.0590]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.384\n",
            "VF res: tensor([[ 0.1361, -0.1182, -0.0898,  0.0710,  0.0592],\n",
            "        [ 0.1361, -0.1182, -0.0898,  0.0710,  0.0592],\n",
            "        [ 0.1361, -0.1182, -0.0898,  0.0710,  0.0592]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.387\n",
            "VF res: tensor([[ 0.1366, -0.1195, -0.0897,  0.0728,  0.0594],\n",
            "        [ 0.1366, -0.1195, -0.0897,  0.0728,  0.0594],\n",
            "        [ 0.1366, -0.1195, -0.0897,  0.0728,  0.0594]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.387\n",
            "VF res: tensor([[ 0.1366, -0.1195, -0.0897,  0.0727,  0.0594],\n",
            "        [ 0.1366, -0.1195, -0.0897,  0.0727,  0.0594],\n",
            "        [ 0.1366, -0.1195, -0.0897,  0.0727,  0.0594]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.395\n",
            "VF res: tensor([[ 0.1394, -0.1232, -0.0884,  0.0769,  0.0596],\n",
            "        [ 0.1394, -0.1232, -0.0884,  0.0769,  0.0596],\n",
            "        [ 0.1394, -0.1232, -0.0884,  0.0769,  0.0596]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.399\n",
            "VF res: tensor([[ 0.1406, -0.1250, -0.0879,  0.0791,  0.0597],\n",
            "        [ 0.1406, -0.1250, -0.0879,  0.0791,  0.0597],\n",
            "        [ 0.1406, -0.1250, -0.0879,  0.0791,  0.0597]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.417\n",
            "VF res: tensor([[ 0.1436, -0.1295, -0.0890,  0.0930,  0.0633],\n",
            "        [ 0.1436, -0.1295, -0.0890,  0.0930,  0.0633],\n",
            "        [ 0.1436, -0.1295, -0.0890,  0.0930,  0.0633]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.420\n",
            "VF res: tensor([[ 0.1442, -0.1301, -0.0891,  0.0955,  0.0637],\n",
            "        [ 0.1442, -0.1301, -0.0891,  0.0955,  0.0637],\n",
            "        [ 0.1442, -0.1301, -0.0891,  0.0955,  0.0637]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.423\n",
            "VF res: tensor([[ 0.1446, -0.1294, -0.0894,  0.0994,  0.0641],\n",
            "        [ 0.1446, -0.1294, -0.0894,  0.0994,  0.0641],\n",
            "        [ 0.1446, -0.1294, -0.0894,  0.0994,  0.0641]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.423\n",
            "VF res: tensor([[ 0.1446, -0.1293, -0.0895,  0.0993,  0.0641],\n",
            "        [ 0.1446, -0.1293, -0.0895,  0.0993,  0.0641],\n",
            "        [ 0.1446, -0.1293, -0.0895,  0.0993,  0.0641]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.430\n",
            "VF res: tensor([[ 0.1456, -0.1268, -0.0898,  0.1103,  0.0650],\n",
            "        [ 0.1456, -0.1268, -0.0898,  0.1103,  0.0650],\n",
            "        [ 0.1456, -0.1268, -0.0898,  0.1103,  0.0650]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.434\n",
            "VF res: tensor([[ 0.1461, -0.1254, -0.0900,  0.1153,  0.0655],\n",
            "        [ 0.1461, -0.1254, -0.0900,  0.1153,  0.0655],\n",
            "        [ 0.1461, -0.1254, -0.0900,  0.1153,  0.0655]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.445\n",
            "VF res: tensor([[ 0.1483, -0.1154, -0.0894,  0.1342,  0.0682],\n",
            "        [ 0.1483, -0.1154, -0.0894,  0.1342,  0.0682],\n",
            "        [ 0.1483, -0.1154, -0.0894,  0.1342,  0.0682]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.445\n",
            "VF res: tensor([[ 0.1478, -0.1127, -0.0883,  0.1374,  0.0688],\n",
            "        [ 0.1478, -0.1127, -0.0883,  0.1374,  0.0688],\n",
            "        [ 0.1478, -0.1127, -0.0883,  0.1374,  0.0688]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.445\n",
            "VF res: tensor([[ 0.1471, -0.1094, -0.0868,  0.1415,  0.0698],\n",
            "        [ 0.1471, -0.1094, -0.0868,  0.1415,  0.0698],\n",
            "        [ 0.1471, -0.1094, -0.0868,  0.1415,  0.0698]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.445\n",
            "VF res: tensor([[ 0.1471, -0.1093, -0.0867,  0.1415,  0.0698],\n",
            "        [ 0.1471, -0.1093, -0.0867,  0.1415,  0.0698],\n",
            "        [ 0.1471, -0.1093, -0.0867,  0.1415,  0.0698]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.449\n",
            "VF res: tensor([[ 0.1446, -0.0998, -0.0790,  0.1567,  0.0739],\n",
            "        [ 0.1446, -0.0998, -0.0790,  0.1567,  0.0739],\n",
            "        [ 0.1446, -0.0998, -0.0790,  0.1567,  0.0739]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.452\n",
            "VF res: tensor([[ 0.1446, -0.0958, -0.0755,  0.1635,  0.0751],\n",
            "        [ 0.1446, -0.0958, -0.0755,  0.1635,  0.0751],\n",
            "        [ 0.1446, -0.0958, -0.0755,  0.1635,  0.0751]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.471\n",
            "VF res: tensor([[ 0.1450, -0.0735, -0.0507,  0.1998,  0.0716],\n",
            "        [ 0.1450, -0.0735, -0.0507,  0.1998,  0.0716],\n",
            "        [ 0.1450, -0.0735, -0.0507,  0.1998,  0.0716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.476\n",
            "VF res: tensor([[ 0.1454, -0.0698, -0.0442,  0.2062,  0.0699],\n",
            "        [ 0.1454, -0.0698, -0.0442,  0.2062,  0.0699],\n",
            "        [ 0.1454, -0.0698, -0.0442,  0.2062,  0.0699]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.480\n",
            "VF res: tensor([[ 0.1454, -0.0641, -0.0372,  0.2134,  0.0687],\n",
            "        [ 0.1454, -0.0641, -0.0372,  0.2134,  0.0687],\n",
            "        [ 0.1454, -0.0641, -0.0372,  0.2134,  0.0687]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.479\n",
            "VF res: tensor([[ 0.1446, -0.0631, -0.0381,  0.2128,  0.0695],\n",
            "        [ 0.1446, -0.0631, -0.0381,  0.2128,  0.0695],\n",
            "        [ 0.1446, -0.0631, -0.0381,  0.2128,  0.0695]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.480\n",
            "VF res: tensor([[ 0.1446, -0.0621, -0.0369,  0.2141,  0.0693],\n",
            "        [ 0.1446, -0.0621, -0.0369,  0.2141,  0.0693],\n",
            "        [ 0.1446, -0.0621, -0.0369,  0.2141,  0.0693]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.480\n",
            "VF res: tensor([[ 0.1446, -0.0616, -0.0363,  0.2147,  0.0692],\n",
            "        [ 0.1446, -0.0616, -0.0363,  0.2147,  0.0692],\n",
            "        [ 0.1446, -0.0616, -0.0363,  0.2147,  0.0692]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.483\n",
            "VF res: tensor([[ 0.1445, -0.0592, -0.0333,  0.2178,  0.0686],\n",
            "        [ 0.1445, -0.0592, -0.0333,  0.2178,  0.0686],\n",
            "        [ 0.1445, -0.0592, -0.0333,  0.2178,  0.0686]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.483\n",
            "VF res: tensor([[ 0.1445, -0.0587, -0.0328,  0.2184,  0.0685],\n",
            "        [ 0.1445, -0.0587, -0.0328,  0.2184,  0.0685],\n",
            "        [ 0.1445, -0.0587, -0.0328,  0.2184,  0.0685]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.484\n",
            "VF res: tensor([[ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684],\n",
            "        [ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684],\n",
            "        [ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "VF Result norm: 0.484\n",
            "VF res: tensor([[ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684],\n",
            "        [ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684],\n",
            "        [ 0.1445, -0.0582, -0.0321,  0.2191,  0.0684]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "{'n_f_evals': tensor([56, 56, 56]), 'n_steps': tensor([9, 9, 9]), 'n_accepted': tensor([9, 9, 9]), 'n_initialized': tensor([10, 10, 10])}\n",
            "Max absolute difference 0.9794543981552124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Backbone_mean(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_dim: int = 32):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "        embedding = batch['embedding'] # [batch_size, time, hidden_dim]\n",
        "        mask = batch['mask'] # [batch_size, time] 1 for good\n",
        "\n",
        "        aggregated = (embedding * mask[:, :, None]).sum(axis=1) / mask.sum(axis=1, keepdims=True)\n",
        "        # output: [batch_size, hidden_dim]\n",
        "\n",
        "        return {\n",
        "            'mask': mask,\n",
        "            'embedding': aggregated\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "T = 20\n",
        "hidden_dim = 4\n",
        "\n",
        "bb = Backbone_mean()\n",
        "\n",
        "mask = (torch.randn(size=(batch_size, T)) > 0)\n",
        "embedding = torch.randn(size=(batch_size, T, hidden_dim))\n",
        "\n",
        "res = bb({'mask': mask, 'embedding': embedding})\n",
        "print(res['embedding'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3teB9-Tsyp1D",
        "outputId": "93abd841-6706-4fe6-cd3e-df718732714f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "po7PmeSe5AzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Код TPP ODE"
      ],
      "metadata": {
        "id": "qbH7Vi09ASVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://torchode.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "id": "cDlcN9dBfe_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие классы необходимо дописать:\n",
        "\n",
        "0. `batch_collator` --- который бы выдвавал батчи в виде TensorDict:  `['time', 'mask', 'type']` из исходных данных\n",
        "\n",
        "1. `self.encoder` --- берет TensorDict с ключами `['time', 'mask', 'type']` и возвращает, батч с добавленным полем `'embedding'`, посчитанным по `type`\n",
        "\n",
        "2. `self.backbone` --- аггрегатор (а что принимает и выдает)?\n"
      ],
      "metadata": {
        "id": "Td8vllp2nliX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаемые параметры модуля ниже:\n",
        "1. `encoder` --- кодирует события в векторы\n",
        "2. `vf` --- векторное поле в ODE (нужно для вычисления финальных эмбеддингов)\n",
        "3. `backbone` ---\n",
        "4. `intensity_layer`"
      ],
      "metadata": {
        "id": "yt64SHp-pDEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Код TPP ODE (старый, nn.Module)"
      ],
      "metadata": {
        "id": "9LVI7b93AbUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "YsPw_jNdRCHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Callable\n",
        "from dataclasses import dataclass\n",
        "from typing import Literal\n",
        "\n",
        "import torch\n",
        "from tensordict import TensorDict\n",
        "from torch import Tensor, nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchode as to\n",
        "from __future__ import annotations\n",
        "\n",
        "# from ..mask_utils import masklast\n",
        "# from ..tensordict_utils import decollate_unpad_batch\n",
        "# from .base import BaseModule\n",
        "\n",
        "# class ODETPPModule(BaseModule):\n",
        "class ODETPPModule(nn.Module): # использовать lightinig_module (чтобы training_step не прописывать) -> training_step, validation_step: в зависимости от того, что проще\n",
        "    vf: nn.Module\n",
        "    neg_count: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        neg_count: int,\n",
        "        n_classes: int,\n",
        "        hidden_dim: int = 128,\n",
        "        device: str = 'cpu',\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.device = device\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.backbone = Backbone_mean()\n",
        "        # self.encoder: cat features -> vector = embedding\n",
        "        # self.backbone: transformer (encoder-only) / aggregate with softmax <--- output is n_classes\n",
        "\n",
        "\n",
        "        ### 1. Define vector field and embedding\n",
        "        self.vf = VectorField(hidden_dim) # vf_factory(self.backbone.output_dim) # vector field what is it???\n",
        "        # self.backbone.output_dim = n_classes???\n",
        "\n",
        "        # Add encoder params to make them learnable.\n",
        "        self.encoder = CatEmbedding(n_classes, hidden_dim)\n",
        "        # self.vf._prev = self.encoder # происходит ДО того, как начинается процесс интегрирования\n",
        "\n",
        "        ### 2. Set up black box ODE solver (from vector factory)\n",
        "        term = to.ODETerm(self.vf)\n",
        "        step_method = to.Dopri5(term=term)\n",
        "        step_size_controller = to.IntegralController(atol=1e-3, rtol=1e-3, term=term)\n",
        "        self.solver = torch.compile(\n",
        "            to.BacksolveAdjoint(term, step_method, step_size_controller) # to.AutoDiffAdjoint may help (faster, but more memory)\n",
        "        )\n",
        "        # self.joint_solver = torch.compile(\n",
        "        #     to.JointBacksolveAdjoint(term, step_method, step_size_controller) # only if all have the same evaluation points\n",
        "        # )\n",
        "\n",
        "\n",
        "        ### 3. Define layers to calculate decoupled conditional intensity\n",
        "        self.intensity_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 1), nn.Sigmoid(), nn.Flatten()\n",
        "        ) # self.encoder.output_dim = hidden_size [in the article authors used softplus]\n",
        "\n",
        "        self.type_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, n_classes),\n",
        "            nn.Softmax(-1),\n",
        "        ) # outputs probabilities of types\n",
        "\n",
        "\n",
        "        self.bb_td = self.backbone # self.backbone.to_tensordictmodule()\n",
        "\n",
        "        self.neg_count = neg_count ###\n",
        "\n",
        "        self.monitor_name = \"val_loss\"\n",
        "        self.monitor_mode = \"min\"\n",
        "\n",
        "    def shared_step(\n",
        "        self,\n",
        "        stage: None | Literal[\"train\"] | Literal[\"val\"] | Literal[\"test\"],\n",
        "        batch: TensorDict,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # batch: dict with keys\n",
        "        '''\n",
        "            batch[0]: should contain:\n",
        "                - timestamps (float)\n",
        "                - corresponding events (int)\n",
        "                - padding mask (used right padding)\n",
        "                - types??? (слудующее событие = сдвиг на 1 вперед???)\n",
        "\n",
        "            encoder(batch):\n",
        "        '''\n",
        "        embedding = self.encoder(batch['types']) # just encodes the events into embeddings\n",
        "\n",
        "\n",
        "\n",
        "        time: Tensor = batch[\"time\"]\n",
        "        nonpadding_mask: Tensor = batch[\"mask\"]\n",
        "        # embedding: Tensor = batch[\"embedding\"]\n",
        "        batch['embedding'] = embedding\n",
        "        types: Tensor = batch['types']\n",
        "\n",
        "        # print(f\"time:\\n{time}\\nmask:\\n{nonpadding_mask}\\nembedding:\\n{embedding}\\ntypes:\\n{types}\\n\")\n",
        "\n",
        "        pos_int, pos_type, neg_int = self.forward(\n",
        "            time, nonpadding_mask, embedding, types\n",
        "        )\n",
        "        loss = pos_int + pos_type + neg_int\n",
        "\n",
        "        # self.log(f\"{stage}_loss\", loss.item())\n",
        "        # self.log(f\"{stage}_posint_loss\", pos_int.item())\n",
        "        # self.log(f\"{stage}_postype_loss\", pos_type.item())\n",
        "        # self.log(f\"{stage}_negint_loss\", neg_int.item())\n",
        "\n",
        "        # if stage == \"train\":\n",
        "        return loss\n",
        "        # else:\n",
        "        #     return self.unnest_merge_detach(\n",
        "        #         pos_intensity_loss_reduced=pos_int,\n",
        "        #         pos_type_loss_reduced=pos_type,\n",
        "        #         neg_intensity_loss_reduced=neg_int,\n",
        "        #     )\n",
        "\n",
        "    def forward(\n",
        "        self, time: Tensor, nonpadding_mask: Tensor, embedding: Tensor, types: Tensor\n",
        "    ):\n",
        "        '''\n",
        "            time: [batch_size, T] <--- timestamps of events (ascending)\n",
        "            nonpadding_mask: [batch_size, T] <--- 1 if value, 0 if mask\n",
        "\n",
        "            types: [batch_size, T] <--- int tensor of event types (NEXT events??? What for the last: no subsequent event)\n",
        "            embedding: [batch_size, T, hidden_dim] <--- embedding of event types, corresponding to according timestemp\n",
        "        '''\n",
        "        # types --- типы след. события\n",
        "        B, T = time.shape # batch_size, T\n",
        "        N = self.neg_count # what is it?\n",
        "\n",
        "        ### 1. Fill padding in time with last times in corresponding timeseries\n",
        "        t_start_int = time # [batch_size, T]\n",
        "        t_end_int = masklast(time, nonpadding_mask, dim=1, keepdim=True).expand(B, T) # [batch_size] -> (copy) [batch_size, T]. Find last timestamp for every timeserie\n",
        "        time[~nonpadding_mask] = t_end_int[~nonpadding_mask] # Fill all padding times with last time in corresponding rimeseries (row)\n",
        "\n",
        "        ### 2. Get total times, at which to calculate the hidden state\n",
        "        t_neg_01 = torch.rand(B, N, device=time.device, dtype=time.dtype) # [batch_size, N] ~ U[0, 1] --- times\n",
        "        t_neg = t_neg_01 * (time[:, -1:] - time[:, :1]) + time[:, :1] # [batch_size, N]: random times in a matrix (each random time within range of t_min, t_max) of corresponding timeseries\n",
        "\n",
        "        t_eval = torch.cat([time, t_neg], dim=1).unsqueeze(1).expand(B, T, -1) # [batch_size, T + N] -> [batch_size, 1, T + N] -> ??? [batch_size, T, ???]\n",
        "\n",
        "\n",
        "        ### 3. Compute hidden states in aforementioned period od times\n",
        "        solution = self.solver.solve(\n",
        "            to.InitialValueProblem(\n",
        "                embedding.flatten(0, -2), # of which shape embedding is???\n",
        "                t_start_int.flatten(), # [batch_size * T]\n",
        "                t_end_int.flatten(), # [batch_size * T] <--- integrate to the end (of the corresp. timeseries)\n",
        "                t_eval.flatten(0, -2), # [a network of points in which to evaluate???]\n",
        "            )\n",
        "        )\n",
        "        # solution.ts:\n",
        "        ys = solution.ys.reshape(B, T, T + N, -1) # [batch_size, T (start time of event), T + N (eval time of event), hidden_dim]\n",
        "        ts = solution.ts.reshape(B, T, T + N) # [batch_size, T (start time of event), T + N (eval time of event)]\n",
        "\n",
        "        ### 4. Filter computed hidden states (some should not be considered). TO NOT TOUCH\n",
        "        # B x T x (T + N)\n",
        "        mask = (t_start_int.unsqueeze(2) <= ts) & (ts < t_end_int.unsqueeze(2)) # eval time should be: older than corresponding start time and younger than corresp end time\n",
        "\n",
        "        # Remove diagonal elements, to prevent data leak\n",
        "        mask[:, range(T), range(T)] = False # we do not evaluate in points, where no integration were held\n",
        "\n",
        "        mask[..., :T] = (\n",
        "            mask[..., :T] & nonpadding_mask.unsqueeze(1) & nonpadding_mask.unsqueeze(2)\n",
        "        )  # B x T x P\n",
        "        mask[..., T:] = mask[..., T:] & nonpadding_mask.unsqueeze(2)  # B x T x N\n",
        "        ys = torch.where(\n",
        "            mask.unsqueeze(-1),\n",
        "            ys,\n",
        "            embedding.unsqueeze(2),\n",
        "        )\n",
        "\n",
        "        # Flattened td B * (P + N) x T x C;\n",
        "        # to be fed into backbone to aggr 1st dim.\n",
        "        td4backbone = TensorDict(\n",
        "            {\n",
        "                \"embedding\": ys.transpose(1, 2).reshape(B * (T + N), T, -1), # [batch_size * (T + N), T, embedding_dim]]\n",
        "                \"mask\": mask.transpose(1, 2).reshape(B * (T + N), T),\n",
        "            },\n",
        "            batch_size=(B * (T + N),),\n",
        "        )\n",
        "\n",
        "        # print(f\"td4backbone.embedding shape: {td4backbone['embedding'].shape}\")\n",
        "\n",
        "        # Aggregate 1st (nut first, but #1 (T) dimension) dimension => B x (T + N) x C\n",
        "        # Pass only non-masked batch elements\n",
        "        batch_mask = td4backbone[\"mask\"].any(1)\n",
        "        aggr_td = self.bb_td(td4backbone[batch_mask]) # [batch_size * (T + N)??, hidden_dim]???]\n",
        "\n",
        "        aggr_embeddings = torch.zeros(\n",
        "            B * (T + N),\n",
        "            self.hidden_dim, # self.backbone.output_dim\n",
        "            device=self.device,\n",
        "            dtype=ys.dtype,\n",
        "        )\n",
        "        aggr_embeddings[batch_mask] = aggr_td[\"embedding\"]\n",
        "\n",
        "\n",
        "        aggr_embeddings = aggr_embeddings.reshape(B, (T + N), -1) # [batch_size, T + N, hidden_dim] ???\n",
        "\n",
        "\n",
        "        ### 5. Calculate loss using computed embeddings\n",
        "        pos, neg = torch.split(aggr_embeddings, [T, N], dim=1) # [batch_size, T, hidden_dim], [batch_size, N, hidden_dim]\n",
        "\n",
        "        # intensity loss\n",
        "        pos_intensity_loss = -torch.log(self.intensity_layer(pos))\n",
        "\n",
        "        # event type loss\n",
        "        pos_type_loss = F.cross_entropy(\n",
        "            self.type_layer(pos).flatten(0, -2),\n",
        "            types.flatten().long(),\n",
        "            reduction=\"none\",\n",
        "            ignore_index=0,\n",
        "        ).reshape(B, T)\n",
        "        neg_intensity_loss: Tensor = self.intensity_layer(neg)\n",
        "\n",
        "        pos_intensity_loss_reduced = pos_intensity_loss[nonpadding_mask].sum(-1).mean()\n",
        "        pos_type_loss_reduced = pos_type_loss[nonpadding_mask].sum(-1).mean()\n",
        "\n",
        "        neg_intensity_loss_reduced = (neg_intensity_loss.mean(-1) * time[:, -1]).mean()\n",
        "\n",
        "        return (\n",
        "            pos_intensity_loss_reduced,\n",
        "            pos_type_loss_reduced,\n",
        "            neg_intensity_loss_reduced,\n",
        "        )\n",
        "\n",
        "#     def predict_step(\n",
        "#         self, batch: TensorDict, *args: torch.Any, **kwargs: torch.Any\n",
        "#     ) -> torch.Any:\n",
        "#         batch = self.encoder(batch)\n",
        "#         time: Tensor = batch[\"time\"]\n",
        "#         mask: Tensor = batch[\"mask\"]\n",
        "#         embedding: Tensor = batch[\"embedding\"]\n",
        "\n",
        "#         t_end = masklast(time, mask, dim=1, keepdim=True).expand_as(time)\n",
        "#         time[~mask] = t_end[~mask]\n",
        "#         trajectory_event = self.joint_solver.solve(\n",
        "#             to.InitialValueProblem(\n",
        "#                 y0=embedding.flatten(0, -2),\n",
        "#                 t_start=time.flatten(),\n",
        "#                 t_end=t_end.flatten(),\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#         embedding = torch.where(\n",
        "#             (time == t_end).unsqueeze(-1),\n",
        "#             embedding,\n",
        "#             trajectory_event.ys[:, -1].view_as(embedding),\n",
        "#         )\n",
        "\n",
        "#         batch = self.bb_td(batch)\n",
        "#         return decollate_unpad_batch(batch.detach().cpu())\n",
        "\n",
        "# # decollate_unpad_batch --- удаляет паддинг"
      ],
      "metadata": {
        "id": "k64ppvHWqsuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_count = 20\n",
        "n_classes = 2\n",
        "hidden_dim = 128\n",
        "device = 'cpu'\n",
        "\n",
        "tpp = ODETPPModule(\n",
        "    neg_count=neg_count,\n",
        "    n_classes=n_classes,\n",
        "    hidden_dim=hidden_dim,\n",
        "    device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "z6Lnva9e5uEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "T = 5\n",
        "\n",
        "time = torch.randn(size=(batch_size, T))\n",
        "nonpadding_mask = (torch.ones_like(time) > 0)\n",
        "types = torch.randint(0, n_classes, size=(batch_size, T))\n",
        "\n",
        "embedding = tpp.encoder(types)\n",
        "\n",
        "forw_res = tpp.forward(time, nonpadding_mask, embedding, types)\n",
        "forw_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm1pBkSM6Bsa",
        "outputId": "4c3c4d94-cc62-49fe-cb26-4e6026435cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(inf, grad_fn=<MeanBackward0>),\n",
              " tensor(3.2976, grad_fn=<MeanBackward0>),\n",
              " tensor(0.4410, grad_fn=<MeanBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nonpadding_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qeiaSLuTuKS",
        "outputId": "77ae77c0-b279-4b60-f5d5-545867c41c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True],\n",
              "        [True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpp.shared_step(\"train\", {'time': time, 'mask': nonpadding_mask, 'types': types})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIS6CWBnSmZi",
        "outputId": "594e68ed-338c-4a8a-a156-d5a3d6c045dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.6109, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8hUJIO9S0Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forw_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxkZXIF760ij",
        "outputId": "df26e624-7b9c-497a-ede4-17878f027bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(7.0654, grad_fn=<MeanBackward0>),\n",
              " tensor(4.3057, grad_fn=<MeanBackward0>),\n",
              " tensor(-0.8223, grad_fn=<MeanBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(forw_res[0] + forw_res[1] + forw_res[2]).backward()"
      ],
      "metadata": {
        "id": "1mA4hVJw8KlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Код TPP ODE (новый, Lightning)"
      ],
      "metadata": {
        "id": "aGExMFALAmtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Callable\n",
        "from dataclasses import dataclass\n",
        "from typing import Literal\n",
        "\n",
        "import torch\n",
        "from tensordict import TensorDict\n",
        "from torch import Tensor, nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchode as to\n",
        "from __future__ import annotations\n",
        "from torchmetrics import MetricCollection\n",
        "\n",
        "from torch.optim import AdamW\n",
        "import pytorch_lightning as pl\n",
        "from functools import partial\n",
        "\n",
        "EPS = 1e-6\n",
        "\n",
        "# from ..mask_utils import masklast\n",
        "# from ..tensordict_utils import decollate_unpad_batch\n",
        "# from .base import BaseModule\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "# class ODETPPModule(BaseModule):\n",
        "class ODETPPModule(pl.LightningModule): # использовать lightinig_module (чтобы training_step не прописывать) -> training_step, validation_step: в зависимости от того, что проще\n",
        "    vf: nn.Module\n",
        "    neg_count: int\n",
        "    # device: str\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        neg_count: int,\n",
        "        n_classes: int,\n",
        "        hidden_dim: int = 128,\n",
        "        # device: str = 'cpu',\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        # self.device = device\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.optimizer_partial = partial(AdamW, lr=1e-4)\n",
        "        self.scheduler_partial = False\n",
        "\n",
        "        self.backbone = Backbone_mean()\n",
        "        # self.encoder: cat features -> vector = embedding\n",
        "        # self.backbone: transformer (encoder-only) / aggregate with softmax <--- output is n_classes\n",
        "\n",
        "\n",
        "        ### 1. Define vector field and embedding\n",
        "        self.vf = VectorField(hidden_dim) # vf_factory(self.backbone.output_dim) # vector field what is it???\n",
        "        # self.backbone.output_dim = n_classes???\n",
        "\n",
        "        # Add encoder params to make them learnable.\n",
        "        self.encoder = CatEmbedding(n_classes, hidden_dim)\n",
        "        # self.vf._prev = self.encoder # происходит ДО того, как начинается процесс интегрирования\n",
        "\n",
        "        ### 2. Set up black box ODE solver (from vector factory)\n",
        "        term = to.ODETerm(self.vf)\n",
        "        step_method = to.Dopri5(term=term)\n",
        "        step_size_controller = to.IntegralController(atol=1e-3, rtol=1e-3, term=term)\n",
        "        self.solver = torch.compile(\n",
        "            to.BacksolveAdjoint(term, step_method, step_size_controller) # to.AutoDiffAdjoint may help (faster, but more memory)\n",
        "        )\n",
        "        # self.joint_solver = torch.compile(\n",
        "        #     to.JointBacksolveAdjoint(term, step_method, step_size_controller) # only if all have the same evaluation points\n",
        "        # )\n",
        "\n",
        "\n",
        "        ### 3. Define layers to calculate decoupled conditional intensity\n",
        "        self.intensity_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 1), nn.Sigmoid(), nn.Flatten()\n",
        "        ) # self.encoder.output_dim = hidden_size [in the article authors used softplus]\n",
        "\n",
        "        self.type_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, n_classes),\n",
        "            nn.Softmax(-1),\n",
        "        ) # outputs probabilities of types\n",
        "\n",
        "\n",
        "        self.bb_td = self.backbone # self.backbone.to_tensordictmodule()\n",
        "\n",
        "        self.neg_count = neg_count ###\n",
        "\n",
        "        self.monitor_name = \"val_loss\"\n",
        "        self.monitor_mode = \"min\"\n",
        "\n",
        "    def shared_step(\n",
        "        self,\n",
        "        stage: None | Literal[\"train\"] | Literal[\"val\"] | Literal[\"test\"],\n",
        "        batch: TensorDict,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # batch: dict with keys\n",
        "        '''\n",
        "            batch[0]: should contain:\n",
        "                - timestamps (float)\n",
        "                - corresponding events (int)\n",
        "                - padding mask (used right padding)\n",
        "                - types??? (слудующее событие = сдвиг на 1 вперед???)\n",
        "\n",
        "            encoder(batch):\n",
        "        '''\n",
        "        print(f\"Types: {batch['types']}\")\n",
        "        embedding = self.encoder(batch['types']) # just encodes the events into embeddings\n",
        "        print(f\"embedding: {embedding}\")\n",
        "\n",
        "        if embedding.flatten().isnan().any():\n",
        "            return 0\n",
        "\n",
        "\n",
        "        time: Tensor = batch[\"time\"]\n",
        "        nonpadding_mask: Tensor = batch[\"mask\"]\n",
        "        # embedding: Tensor = batch[\"embedding\"]\n",
        "        batch['embedding'] = embedding\n",
        "        types: Tensor = batch['types']\n",
        "\n",
        "        # print(f\"time:\\n{time}\\nmask:\\n{nonpadding_mask}\\nembedding:\\n{embedding}\\ntypes:\\n{types}\\n\")\n",
        "\n",
        "        pos_int, pos_type, neg_int = self.forward(\n",
        "            time, nonpadding_mask, embedding, types\n",
        "        )\n",
        "        loss = pos_int + pos_type + neg_int\n",
        "\n",
        "        self.log(f\"{stage}_loss\", loss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(f\"{stage}_posint_loss\", pos_int.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(f\"{stage}_postype_loss\", pos_type.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(f\"{stage}_negint_loss\", neg_int.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        # if stage == \"train\":\n",
        "        print(f\"------------------Loss: {loss}\")\n",
        "        return loss\n",
        "        # else:\n",
        "        #     return self.unnest_merge_detach(\n",
        "        #         pos_intensity_loss_reduced=pos_int,\n",
        "        #         pos_type_loss_reduced=pos_type,\n",
        "        #         neg_intensity_loss_reduced=neg_int,\n",
        "        #     )\n",
        "\n",
        "    def forward(\n",
        "        self, time: Tensor, nonpadding_mask: Tensor, embedding: Tensor, types: Tensor\n",
        "    ):\n",
        "        '''\n",
        "            time: [batch_size, T] <--- timestamps of events (ascending)\n",
        "            nonpadding_mask: [batch_size, T] <--- 1 if value, 0 if mask\n",
        "\n",
        "            types: [batch_size, T] <--- int tensor of event types (NEXT events??? What for the last: no subsequent event)\n",
        "            embedding: [batch_size, T, hidden_dim] <--- embedding of event types, corresponding to according timestemp\n",
        "        '''\n",
        "        # types --- типы след. события\n",
        "        B, T = time.shape # batch_size, T\n",
        "        N = self.neg_count # what is it?\n",
        "\n",
        "        ### 1. Fill padding in time with last times in corresponding timeseries\n",
        "        t_start_int = time # [batch_size, T]\n",
        "        t_end_int = masklast(time, nonpadding_mask, dim=1, keepdim=True).expand(B, T) # [batch_size] -> (copy) [batch_size, T]. Find last timestamp for every timeserie\n",
        "        time[~nonpadding_mask] = t_end_int[~nonpadding_mask] # Fill all padding times with last time in corresponding rimeseries (row)\n",
        "\n",
        "        ### 2. Get total times, at which to calculate the hidden state\n",
        "        t_neg_01 = torch.rand(B, N, device=time.device, dtype=time.dtype) # [batch_size, N] ~ U[0, 1] --- times\n",
        "        t_neg = t_neg_01 * (time[:, -1:] - time[:, :1]) + time[:, :1] # [batch_size, N]: random times in a matrix (each random time within range of t_min, t_max) of corresponding timeseries\n",
        "\n",
        "        t_eval = torch.cat([time, t_neg], dim=1).unsqueeze(1).expand(B, T, -1) # [batch_size, T + N] -> [batch_size, 1, T + N] -> ??? [batch_size, T, ???]\n",
        "\n",
        "        # print(f\"t_start_int: {get_stats(t_start_int)}\")\n",
        "        # print(f\"t_end_int: {get_stats(t_end_int)}\")\n",
        "        # print(f\"t_eval: {get_stats(t_eval)}\")\n",
        "        print(f\"t_start_int: {(t_start_int)}\")\n",
        "        print(f\"t_end_int: {(t_end_int)}\")\n",
        "        print(f\"t_eval: {(t_eval)}\")\n",
        "        print(embedding.flatten(0, -2))\n",
        "        print(t_start_int.flatten())\n",
        "        print(t_end_int.flatten())\n",
        "        print(t_eval.flatten(0, -2))\n",
        "\n",
        "        assert (t_start_int.flatten() <= t_end_int.flatten()).all()\n",
        "\n",
        "        # t_end_int[t_end_int == t_start_int] = t_end_int[t_end_int == t_start_int] + EPS\n",
        "\n",
        "        ### 3. Compute hidden states in aforementioned period od times\n",
        "        solution = self.solver.solve(\n",
        "            to.InitialValueProblem(\n",
        "                embedding.flatten(0, -2), # of which shape embedding is???\n",
        "                t_start_int.flatten(), # [batch_size * T]\n",
        "                t_end_int.flatten(), # [batch_size * T] <--- integrate to the end (of the corresp. timeseries)\n",
        "                t_eval.flatten(0, -2), # [a network of points in which to evaluate???]\n",
        "            )\n",
        "        )\n",
        "        # solution.ts:\n",
        "        ys = solution.ys.reshape(B, T, T + N, -1) # [batch_size, T (start time of event), T + N (eval time of event), hidden_dim]\n",
        "        ts = solution.ts.reshape(B, T, T + N) # [batch_size, T (start time of event), T + N (eval time of event)]\n",
        "\n",
        "        ### 4. Filter computed hidden states (some should not be considered). TO NOT TOUCH\n",
        "        # B x T x (T + N)\n",
        "        mask = (t_start_int.unsqueeze(2) <= ts) & (ts < t_end_int.unsqueeze(2)) # eval time should be: older than corresponding start time and younger than corresp end time\n",
        "\n",
        "        # Remove diagonal elements, to prevent data leak\n",
        "        mask[:, range(T), range(T)] = False # we do not evaluate in points, where no integration were held\n",
        "\n",
        "        mask[..., :T] = (\n",
        "            mask[..., :T] & nonpadding_mask.unsqueeze(1) & nonpadding_mask.unsqueeze(2)\n",
        "        )  # B x T x P\n",
        "        mask[..., T:] = mask[..., T:] & nonpadding_mask.unsqueeze(2)  # B x T x N\n",
        "        ys = torch.where(\n",
        "            mask.unsqueeze(-1),\n",
        "            ys,\n",
        "            embedding.unsqueeze(2),\n",
        "        )\n",
        "\n",
        "        print(f\"ys: {get_stats(ys)}\")\n",
        "        print(f\"ts: {get_stats(ts)}\")\n",
        "\n",
        "        # Flattened td B * (P + N) x T x C;\n",
        "        # to be fed into backbone to aggr 1st dim.\n",
        "        td4backbone = TensorDict(\n",
        "            {\n",
        "                \"embedding\": ys.transpose(1, 2).reshape(B * (T + N), T, -1), # [batch_size * (T + N), T, embedding_dim]]\n",
        "                \"mask\": mask.transpose(1, 2).reshape(B * (T + N), T),\n",
        "            },\n",
        "            batch_size=(B * (T + N),),\n",
        "        )\n",
        "\n",
        "        # print(f\"td4backbone.embedding shape: {td4backbone['embedding'].shape}\")\n",
        "\n",
        "        # Aggregate 1st (nut first, but #1 (T) dimension) dimension => B x (T + N) x C\n",
        "        # Pass only non-masked batch elements\n",
        "        batch_mask = td4backbone[\"mask\"].any(1)\n",
        "        aggr_td = self.bb_td(td4backbone[batch_mask]) # [batch_size * (T + N)??, hidden_dim]???]\n",
        "\n",
        "        aggr_embeddings = torch.zeros(\n",
        "            B * (T + N),\n",
        "            self.hidden_dim, # self.backbone.output_dim\n",
        "            device=self.device,\n",
        "            dtype=ys.dtype,\n",
        "        )\n",
        "        aggr_embeddings[batch_mask] = aggr_td[\"embedding\"]\n",
        "\n",
        "\n",
        "        aggr_embeddings = aggr_embeddings.reshape(B, (T + N), -1) # [batch_size, T + N, hidden_dim] ???\n",
        "        print(f\"aggr emb: {get_stats(aggr_embeddings)}\")\n",
        "\n",
        "        ### 5. Calculate loss using computed embeddings\n",
        "        pos, neg = torch.split(aggr_embeddings, [T, N], dim=1) # [batch_size, T, hidden_dim], [batch_size, N, hidden_dim]\n",
        "\n",
        "        # intensity loss\n",
        "        print(f\"POS: {get_stats(pos)}\")\n",
        "        pos_intensity_loss = -torch.log(self.intensity_layer(pos))\n",
        "        print(f\"pos_intensity_loss: {get_stats(pos_intensity_loss)}\")\n",
        "\n",
        "        # event type loss\n",
        "        pos_type_loss = F.cross_entropy(\n",
        "            self.type_layer(pos).flatten(0, -2),\n",
        "            types.flatten().long(),\n",
        "            reduction=\"none\",\n",
        "            ignore_index=0,\n",
        "        ).reshape(B, T)\n",
        "\n",
        "        print(f\"pos_type_loss: {pos_type_loss}\")\n",
        "\n",
        "        neg_intensity_loss: Tensor = self.intensity_layer(neg)\n",
        "\n",
        "        print(f\"neg_intensity_loss: {neg_intensity_loss}\")\n",
        "\n",
        "        pos_intensity_loss_reduced = pos_intensity_loss[nonpadding_mask].sum(-1).mean()\n",
        "        pos_type_loss_reduced = pos_type_loss[nonpadding_mask].sum(-1).mean()\n",
        "\n",
        "        neg_intensity_loss_reduced = (neg_intensity_loss.mean(-1) * time[:, -1]).mean()\n",
        "\n",
        "        return (\n",
        "            pos_intensity_loss_reduced,\n",
        "            pos_type_loss_reduced,\n",
        "            neg_intensity_loss_reduced,\n",
        "        )\n",
        "\n",
        "\n",
        "    def checkpoint_callback(self):\n",
        "        \"\"\"Construct a matching ModelCheckpoint callback.\"\"\"\n",
        "        if not hasattr(self, \"_checkpoint_callback\"):\n",
        "            self._checkpoint_callback = ModelCheckpoint(\n",
        "                monitor=self.monitor_name, mode=self.monitor_mode\n",
        "            )\n",
        "\n",
        "        return self._checkpoint_callback\n",
        "\n",
        "    def load_best_checkpoint(self):\n",
        "        \"\"\"Load best state dict into model.\"\"\"\n",
        "        self.load_state_dict(\n",
        "            torch.load(self._checkpoint_callback.best_model_path)[\"state_dict\"]\n",
        "        )\n",
        "\n",
        "    def init_metrics(self, metric_collection: MetricCollection, *stages: str):\n",
        "        \"\"\"Initialize metrics for each stage.\"\"\"\n",
        "        self.metric_collection = metric_collection\n",
        "        for stage in stages:\n",
        "            setattr(self, f\"{stage}_metrics\", self.metric_collection.clone(stage))\n",
        "\n",
        "    def metrics(self, stage: Literal[\"train\", \"val\", \"test\"] | None):\n",
        "        \"\"\"Get the relevant metrics.\"\"\"\n",
        "        if stage is None:\n",
        "            if self.metric_collection is None:\n",
        "                raise ValueError(\n",
        "                    \"Set metric_factory before calling metrics with stage=None.\"\n",
        "                )\n",
        "            return self.metric_collection.clone(\"\")\n",
        "\n",
        "        return getattr(self, f\"{stage}_metrics\")\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        \"\"\"Run the training step of this model.\"\"\"\n",
        "        return self.shared_step(\"train\", batch, batch_idx, dataloader_idx)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        \"\"\"Enable artifact logging.\"\"\"\n",
        "        batch = self.shared_step(\"val\", batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        \"\"\"Run the test step of this model.\"\"\"\n",
        "        return self.shared_step(\"test\", batch, batch_idx, dataloader_idx)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Configure optimizers.\"\"\"\n",
        "        optimizer = self.optimizer_partial(self.parameters())\n",
        "        if self.scheduler_partial:\n",
        "            scheduler = self.scheduler_partial(optimizer)\n",
        "            scheduler_config = dict(scheduler=scheduler, **self.scheduler_config)\n",
        "            return [optimizer], [scheduler_config]\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def predict_step(\n",
        "        self, batch: TensorDict, *args: torch.Any, **kwargs: torch.Any\n",
        "    ) -> torch.Any:\n",
        "        batch = self.encoder(batch)\n",
        "        time: Tensor = batch[\"time\"]\n",
        "        mask: Tensor = batch[\"mask\"]\n",
        "        embedding: Tensor = batch[\"embedding\"]\n",
        "\n",
        "        t_end = masklast(time, mask, dim=1, keepdim=True).expand_as(time)\n",
        "        time[~mask] = t_end[~mask]\n",
        "        trajectory_event = self.joint_solver.solve(\n",
        "            to.InitialValueProblem(\n",
        "                y0=embedding.flatten(0, -2),\n",
        "                t_start=time.flatten(),\n",
        "                t_end=t_end.flatten(),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        embedding = torch.where(\n",
        "            (time == t_end).unsqueeze(-1),\n",
        "            embedding,\n",
        "            trajectory_event.ys[:, -1].view_as(embedding),\n",
        "        ) # then aggregate and get loss/logits\n",
        "\n",
        "        batch = self.bb_td(batch)\n",
        "        return decollate_unpad_batch(batch.detach().cpu())\n",
        "\n",
        "# # decollate_unpad_batch --- удаляет паддинг"
      ],
      "metadata": {
        "id": "GbK8mc3K8NHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stats(t):\n",
        "    print(f\"{t.flatten().min()}---{t.flatten().max()}; {t.flatten().isnan().any()}\")\n",
        "\n",
        "def get_stats(t):\n",
        "    return f\"{t.flatten().min()}---{t.flatten().max()}; {t.flatten().isnan().any()}\""
      ],
      "metadata": {
        "id": "XXxmptasFt72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(size=(2, 3, 4)).flatten().isnan()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJzG57yAF6XI",
        "outputId": "1ba44444-21fa-48a7-c79d-e19600cee552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpp.encoder(torch.tensor([[1, 0, 0],\n",
        "        [0, 0, 0]]).cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzL5hik2Kc3u",
        "outputId": "0625aa69-7d84-40eb-bd56-2606848d4ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[nan, nan, nan, nan],\n",
              "         [nan, nan, nan, nan],\n",
              "         [nan, nan, nan, nan]],\n",
              "\n",
              "        [[nan, nan, nan, nan],\n",
              "         [nan, nan, nan, nan],\n",
              "         [nan, nan, nan, nan]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for par_name, par in tpp.encoder.named_parameters():\n",
        "    print(par_name, par)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3aX3ubQKjUO",
        "outputId": "e16aaa8e-5e44-4a90-a405-faf6399c5490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding.weight Parameter containing:\n",
            "tensor([[    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [-1.9999,  0.0287, -0.3504,  0.4536],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [-1.0465, -2.5754,  0.8889, -0.2293]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_count = 2\n",
        "n_classes = 10\n",
        "hidden_dim = 4\n",
        "max_length = 3\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "\n",
        "torch_dataset = EventSequenceDataset(dataset, max_length)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "tpp = ODETPPModule(\n",
        "    neg_count=neg_count,\n",
        "    n_classes=n_classes,\n",
        "    hidden_dim=hidden_dim,\n",
        "    # lr=lr,\n",
        "    # device=device,\n",
        ")\n",
        "\n",
        "opt = tpp.configure_optimizers()"
      ],
      "metadata": {
        "id": "Ou3krA9_Ldoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "T = 5\n",
        "\n",
        "times = torch.randn(size=(batch_size, T))\n",
        "time = torch.zeros_like(times)\n",
        "\n",
        "for i in range(batch_size):\n",
        "    time[i] = torch.tensor(sorted(times[i]))\n",
        "    time[i] = time[i] - time[i].min()\n",
        "    time[i] = time[i] / time[i].max()\n",
        "\n",
        "nonpadding_mask = (torch.ones_like(time) > 0)\n",
        "types = torch.randint(0, n_classes, size=(batch_size, T))\n",
        "\n",
        "embedding = tpp.encoder(types)\n",
        "\n",
        "forw_res = tpp.forward(time, nonpadding_mask, embedding, types)\n",
        "forw_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGHg6hpOLBB-",
        "outputId": "a9b7b882-42d1-4a5b-873b-b062a517fb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t_start_int: 0.0---1.0; False\n",
            "t_end_int: 1.0---1.0; False\n",
            "t_eval: 0.0---1.0; False\n",
            "tensor([[ 1.3201,  0.5140, -0.6002,  0.3601],\n",
            "        [ 0.6993,  0.9179,  0.5372,  1.9960],\n",
            "        [ 0.6993,  0.9179,  0.5372,  1.9960],\n",
            "        [-1.1232,  0.3883, -0.1905, -1.4667],\n",
            "        [-0.7341,  0.7822,  0.7711,  0.0690],\n",
            "        [ 0.3828, -0.4969, -0.6063,  0.4326],\n",
            "        [ 0.6993,  0.9179,  0.5372,  1.9960],\n",
            "        [ 0.8078,  0.9735,  1.9105,  0.2795],\n",
            "        [ 1.3201,  0.5140, -0.6002,  0.3601],\n",
            "        [ 0.3828, -0.4969, -0.6063,  0.4326]], grad_fn=<ViewBackward0>)\n",
            "tensor([0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0000, 0.0615, 0.1327, 0.1671,\n",
            "        1.0000])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor([[0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0830, 0.4389],\n",
            "        [0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0830, 0.4389],\n",
            "        [0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0830, 0.4389],\n",
            "        [0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0830, 0.4389],\n",
            "        [0.0000, 0.0243, 0.1964, 0.8294, 1.0000, 0.0830, 0.4389],\n",
            "        [0.0000, 0.0615, 0.1327, 0.1671, 1.0000, 0.9487, 0.8007],\n",
            "        [0.0000, 0.0615, 0.1327, 0.1671, 1.0000, 0.9487, 0.8007],\n",
            "        [0.0000, 0.0615, 0.1327, 0.1671, 1.0000, 0.9487, 0.8007],\n",
            "        [0.0000, 0.0615, 0.1327, 0.1671, 1.0000, 0.9487, 0.8007],\n",
            "        [0.0000, 0.0615, 0.1327, 0.1671, 1.0000, 0.9487, 0.8007]])\n",
            "ys: -1.4853448867797852---2.000542163848877; False\n",
            "ts: 0.0---1.0; False\n",
            "aggr emb: -0.604275643825531---1.4065223932266235; False\n",
            "POS: -0.604275643825531---1.3702826499938965; False\n",
            "pos_intensity_loss: 0.7036600112915039---1.0475714206695557; False\n",
            "pos_type_loss: tensor([[2.2802, 2.2559, 2.2301, 2.3287, 2.3222],\n",
            "        [2.2940, 2.3303, 2.3112, 2.2794, 2.2902]], grad_fn=<ViewBackward0>)\n",
            "neg_intensity_loss: tensor([[0.3613, 0.3667],\n",
            "        [0.4302, 0.4300]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-a9e5f2e3b11e>:175: UserWarning: Use of index_put_ on expanded tensors is deprecated. Please clone() the tensor before performing this operation. This also applies to advanced indexing e.g. tensor[indices] = tensor (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:792.)\n",
            "  t_end_int[t_end_int == t_start_int] = t_end_int[t_end_int == t_start_int] + EPS\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(8.8851, grad_fn=<MeanBackward0>),\n",
              " tensor(22.9223, grad_fn=<MeanBackward0>),\n",
              " tensor(0.3970, grad_fn=<MeanBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = forw_res[0] + forw_res[1] + forw_res[2]\n",
        "print(loss)\n",
        "loss.backward()\n",
        "opt.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V069IUFLFdV",
        "outputId": "99802680-0f97-435f-9742-c75202a58e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(32.2044, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt.zero_grad()"
      ],
      "metadata": {
        "id": "Ar2nRS-gQIe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8q-0ShslQKBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt.step()"
      ],
      "metadata": {
        "id": "qgiNu0j7P2Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eS1GuBsfP2y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7ZcklOr4NA7C",
        "outputId": "afae007e-7172-4462-9fd7-3985d8fbeaa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-52a0569421b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpp.optimizer_partial.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "tI59HyZGNjw2",
        "outputId": "854ffc4d-d1b8-4e86-b7aa-561ebfe892be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'functools.partial' object has no attribute 'step'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-b3b6c7ca29aa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_partial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'functools.partial' object has no attribute 'step'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wcfTC9orNBtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for par_name, par in tpp.encoder.named_parameters():\n",
        "    print(par_name, par)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTePR8N3M79U",
        "outputId": "fc220e35-11ae-427e-b2ef-d6c02c268cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding.weight Parameter containing:\n",
            "tensor([[    nan,     nan,     nan,     nan],\n",
            "        [ 0.8081, -0.2189,  1.6855,  1.2377],\n",
            "        [    nan,     nan,     nan,     nan],\n",
            "        [-1.3312,  1.4097, -1.7261, -0.3673],\n",
            "        [ 1.2208,  2.1358, -0.7320,  0.7653],\n",
            "        [ 0.0409,  2.2860,  1.1739,  0.4008],\n",
            "        [ 0.4618,  1.2737, -0.2647,  1.0148],\n",
            "        [ 1.1140, -0.7972,  0.5095,  0.0975],\n",
            "        [ 0.4329,  0.5912,  0.5195,  1.8779],\n",
            "        [-0.1359, -0.5337,  1.0371, -2.5003]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_count = 2\n",
        "n_classes = 10\n",
        "hidden_dim = 4\n",
        "max_length = 3\n",
        "batch_size = 2\n",
        "lr = 1e-4\n",
        "\n",
        "torch_dataset = EventSequenceDataset(dataset, max_length)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "tpp = ODETPPModule(\n",
        "    neg_count=neg_count,\n",
        "    n_classes=n_classes,\n",
        "    hidden_dim=hidden_dim,\n",
        "    # lr=lr,\n",
        "    # device=device,\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(accelerator=\"gpu\")\n",
        "trainer.fit(model=tpp.cuda(), train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "u0B2Fd0mDyCp",
        "outputId": "aa22a394-a74d-476e-a6f2-ce7ae7bb7145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Backbone_mean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-746cdd41828c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m tpp = ODETPPModule(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mneg_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-ac347c6a6571>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, neg_count, n_classes, hidden_dim, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackbone_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;31m# self.encoder: cat features -> vector = embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# self.backbone: transformer (encoder-only) / aggregate with softmax <--- output is n_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Backbone_mean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensordict import TensorDict\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "class EventSequenceDataset(Dataset):\n",
        "    def __init__(self, dict_dataset, max_length: int = 100):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path (str): Path to CSV file containing:\n",
        "                - 'timestamps': List of event timestamps\n",
        "                - 'types': List of event type indices\n",
        "                - 'target': Single integer target value\n",
        "        \"\"\"\n",
        "        self.df = dict_dataset\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df[idx]\n",
        "\n",
        "        return {\n",
        "            'time': torch.tensor(row['time'], dtype=torch.float32)[:self.max_length],\n",
        "            'types': torch.tensor(row['type'], dtype=torch.long)[:self.max_length],\n",
        "            'target': torch.tensor(row['target'], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function to pad sequences and create masks\"\"\"\n",
        "    # Separate components\n",
        "    times = [item['time'] for item in batch]\n",
        "    types = [item['types'] for item in batch]\n",
        "    targets = [item['target'] for item in batch]\n",
        "\n",
        "    # Get sequence lengths and determine padding length\n",
        "    lengths = [len(seq) for seq in times]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    # Initialize padded tensors\n",
        "    batch_size = len(batch)\n",
        "    padded_times = torch.zeros((batch_size, max_len), dtype=torch.float32)\n",
        "    padded_types = torch.zeros((batch_size, max_len), dtype=torch.long)\n",
        "    masks = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
        "\n",
        "    # Fill tensors\n",
        "    for i, (t, ty) in enumerate(zip(times, types)):\n",
        "        seq_len = t.shape[0]\n",
        "        padded_times[i, :seq_len] = t\n",
        "        padded_types[i, :seq_len] = ty\n",
        "        masks[i, :seq_len] = True  # Mask where actual data exists\n",
        "\n",
        "    return TensorDict({\n",
        "        'time': padded_times,\n",
        "        'types': padded_types,\n",
        "        'target': torch.stack(targets),\n",
        "        'mask': masks\n",
        "    }, batch_size=batch_size)\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Initialize dataset and dataloader\n",
        "#     dataset = EventSequenceDataset('your_data.csv')\n",
        "#     dataloader = DataLoader(\n",
        "#         dataset,\n",
        "#         batch_size=32,\n",
        "#         shuffle=True,\n",
        "#         collate_fn=collate_fn\n",
        "#     )\n",
        "\n",
        "#     # Test one batch\n",
        "#     batch = next(iter(dataloader))\n",
        "#     print(\"Batch structure:\")\n",
        "#     print(f\"- Time tensor shape: {batch['time'].shape}\")\n",
        "#     print(f\"- Type tensor shape: {batch['type'].shape}\")\n",
        "#     print(f\"- Target tensor shape: {batch['target'].shape}\")\n",
        "#     print(f\"- Mask tensor shape: {batch['non_padding_mask'].shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ogm5A_C6WwSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_dataset = EventSequenceDataset(dataset)"
      ],
      "metadata": {
        "id": "gyCAoSBvbp0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 10\n",
        "torch_dataset = EventSequenceDataset(dataset, max_length)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=5,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "nbs4OkABcHjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataloader))\n",
        "print(\"Batch structure:\")\n",
        "print(f\"- Time tensor shape: {batch['time'].shape}\")\n",
        "print(f\"- Type tensor shape: {batch['types'].shape}\")\n",
        "print(f\"- Target tensor shape: {batch['target'].shape}\")\n",
        "print(f\"- Mask tensor shape: {batch['mask'].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdgnecP8cTZg",
        "outputId": "7c0edcca-a197-4356-865d-2429eda3518c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch structure:\n",
            "- Time tensor shape: torch.Size([5, 10])\n",
            "- Type tensor shape: torch.Size([5, 10])\n",
            "- Target tensor shape: torch.Size([5])\n",
            "- Mask tensor shape: torch.Size([5, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['target']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky0QBhaUcbbb",
        "outputId": "911e9ba3-12fe-41a8-9932-cfa706a7199e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kQ0OJfRBu8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_count = 20\n",
        "n_classes = 10\n",
        "hidden_dim = 16\n",
        "max_length = 10\n",
        "batch_size = 32\n",
        "\n",
        "torch_dataset = EventSequenceDataset(dataset, max_length)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "        torch_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "tpp = ODETPPModule(\n",
        "    neg_count=neg_count,\n",
        "    n_classes=n_classes,\n",
        "    hidden_dim=hidden_dim,\n",
        "    # device=device,\n",
        ")"
      ],
      "metadata": {
        "id": "MXkYEVTtc7vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trx_category_to_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnwnLNYec8gE",
        "outputId": "53d31d45-310f-48a6-9919-74570da08e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(accelerator=\"gpu\")\n",
        "trainer.fit(model=tpp.cuda(), train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "68bb4ddda99f49b5ba922a1dc03c249b",
            "5cd4f09d78a64896990f822dfb5c8ff0",
            "4aad9155ffb34810a9abe3046c74dae2",
            "bc4a4ff1298642d29e2fa5b9c1cd4e2f",
            "ffdf2781ca4244bdb7240b4b408e3a3f",
            "63b357d60d73409f996033f618c710ca",
            "9ca34afbc6ef4596b149877a5c38d192",
            "2bdce0fabc3f40349ec6e4b5faf18b8b",
            "4e47039e7d5a460085fcdcb602167e00",
            "5c172c14511b4915b60bcfbe39a7967e",
            "f2bc939f9ee94f00a8582899910eb8c5"
          ]
        },
        "id": "ZWNqZewLcud-",
        "outputId": "93b1e9d9-39c7-4b5d-89eb-f12977f14166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type            | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0 | backbone        | Backbone_mean   | 0      | train\n",
            "1 | vf              | VectorField     | 2.2 K  | train\n",
            "2 | encoder         | CatEmbedding    | 160    | train\n",
            "3 | solver          | OptimizedModule | 2.2 K  | train\n",
            "4 | intensity_layer | Sequential      | 17     | train\n",
            "5 | type_layer      | Sequential      | 170    | train\n",
            "------------------------------------------------------------\n",
            "2.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "2.5 K     Total params\n",
            "0.010     Total estimated model params size (MB)\n",
            "25        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68bb4ddda99f49b5ba922a1dc03c249b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-170-58b0b68b38ee>:178: UserWarning: Use of index_put_ on expanded tensors is deprecated. Please clone() the tensor before performing this operation. This also applies to advanced indexing e.g. tensor[indices] = tensor (Triggered internally at /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:792.)\n",
            "  t_end_int[t_end_int == t_start_int] = t_end_int[t_end_int == t_start_int] + EPS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Types: tensor([[2, 2, 2, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 6, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 6, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 2],\n",
            "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [6, 0, 0, 0, 0, 6, 2, 2, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 2, 0, 0, 0, 0, 0, 6, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [4, 4, 4, 0, 2, 4, 0, 0, 0, 2],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [3, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [2, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [5, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 2, 0]], device='cuda:0')\n",
            "embedding: tensor([[[ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "         [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "         [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "\n",
            "        [[ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "\n",
            "        [[ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "\n",
            "        [[ 0.2278, -0.5631, -0.6085,  ...,  0.0831,  0.5768, -1.1586],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "\n",
            "        [[ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         ...,\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "         [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "         [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]]],\n",
            "       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n",
            "t_start_int: 0.0---0.21978022158145905; False\n",
            "t_end_int: 0.010781176388263702---0.21978022158145905; False\n",
            "t_eval: 0.0---0.21978022158145905; False\n",
            "tensor([[ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "        [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "        [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "        ...,\n",
            "        [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816],\n",
            "        [ 0.9624,  0.6211,  1.3973,  ...,  0.9484, -2.0470,  0.3931],\n",
            "        [ 0.9720, -0.7735,  1.6274,  ..., -0.2882, -0.8582, -0.0816]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
            "tensor([0.0000e+00, 1.1975e-03, 1.2122e-03, 4.5478e-03, 4.5478e-03, 4.5478e-03,\n",
            "        1.5487e-02, 3.7365e-02, 3.7365e-02, 3.7365e-02, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.3367e-02, 1.3367e-02, 2.6733e-02, 2.6733e-02, 2.6733e-02,\n",
            "        2.6733e-02, 4.0100e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.0870e-02, 2.1739e-02, 2.1739e-02, 2.1739e-02, 2.1739e-02,\n",
            "        0.0000e+00, 5.4202e-05, 7.4088e-04, 7.4088e-04, 7.4088e-04, 7.4088e-04,\n",
            "        7.4088e-04, 1.5655e-02, 1.5655e-02, 1.5655e-02, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0989e-02, 1.0989e-02, 1.0989e-02, 1.0989e-02,\n",
            "        2.1978e-02, 2.1978e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 8.5463e-03, 1.1236e-02, 1.1236e-02, 1.1236e-02,\n",
            "        0.0000e+00, 0.0000e+00, 8.5863e-03, 4.0914e-02, 4.0920e-02, 4.3601e-02,\n",
            "        5.4502e-02, 5.4502e-02, 5.4502e-02, 6.5402e-02, 0.0000e+00, 1.0842e-01,\n",
            "        1.0842e-01, 1.0842e-01, 1.0842e-01, 1.3010e-01, 1.3010e-01, 1.4094e-01,\n",
            "        1.4094e-01, 1.4094e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.6393e-02, 1.6393e-02, 1.6393e-02, 1.6393e-02, 2.4533e-02,\n",
            "        0.0000e+00, 2.5381e-03, 2.5381e-03, 2.5381e-03, 1.1154e-02, 1.3275e-02,\n",
            "        1.3275e-02, 2.4011e-02, 2.4011e-02, 2.4011e-02, 0.0000e+00, 7.3864e-03,\n",
            "        1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02, 2.1739e-02, 2.1739e-02,\n",
            "        2.1739e-02, 2.1739e-02, 0.0000e+00, 0.0000e+00, 2.1739e-02, 2.1739e-02,\n",
            "        2.1739e-02, 2.1739e-02, 2.1739e-02, 2.1739e-02, 3.2609e-02, 3.2609e-02,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        5.6640e-03, 6.6246e-03, 6.6580e-03, 1.0781e-02, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02, 3.2609e-02,\n",
            "        3.2609e-02, 3.2609e-02, 0.0000e+00, 1.3177e-05, 3.8312e-03, 3.8312e-03,\n",
            "        1.4778e-02, 1.4778e-02, 2.5725e-02, 3.6672e-02, 4.7619e-02, 5.8566e-02,\n",
            "        0.0000e+00, 2.8689e-03, 1.0870e-02, 1.0870e-02, 1.2550e-02, 1.2583e-02,\n",
            "        2.1739e-02, 2.7689e-02, 3.2609e-02, 3.2609e-02, 0.0000e+00, 7.6923e-02,\n",
            "        7.6923e-02, 1.3187e-01, 1.3187e-01, 1.3187e-01, 1.5385e-01, 2.0879e-01,\n",
            "        2.1978e-01, 2.1978e-01, 0.0000e+00, 2.3999e-03, 1.0522e-02, 1.3030e-02,\n",
            "        1.8023e-02, 2.0634e-02, 2.3660e-02, 2.3660e-02, 2.3660e-02, 2.8767e-02,\n",
            "        0.0000e+00, 1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02,\n",
            "        1.0870e-02, 1.0870e-02, 2.1739e-02, 2.1739e-02, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02, 1.0870e-02,\n",
            "        3.2609e-02, 3.2609e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6780e-03,\n",
            "        1.1297e-02, 1.1297e-02, 2.2594e-02, 2.2594e-02, 2.2594e-02, 3.3891e-02,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0933e-02, 1.0933e-02,\n",
            "        2.1865e-02, 3.2798e-02, 4.3730e-02, 4.3730e-02, 0.0000e+00, 8.6335e-03,\n",
            "        3.7975e-02, 4.4487e-02, 5.0633e-02, 5.0633e-02, 5.0633e-02, 6.3291e-02,\n",
            "        7.5949e-02, 7.5949e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1494e-02,\n",
            "        1.1494e-02, 1.1494e-02, 2.2989e-02, 4.5977e-02, 4.5977e-02, 4.5977e-02,\n",
            "        0.0000e+00, 2.8391e-03, 2.8391e-03, 1.4710e-02, 1.4710e-02, 1.4710e-02,\n",
            "        1.4710e-02, 1.4710e-02, 2.1491e-02, 2.1501e-02, 0.0000e+00, 0.0000e+00,\n",
            "        1.4027e-02, 2.8054e-02, 4.2081e-02, 4.2081e-02, 4.2081e-02, 5.6108e-02,\n",
            "        5.6108e-02, 5.6108e-02, 0.0000e+00, 0.0000e+00, 1.1236e-02, 1.1236e-02,\n",
            "        2.2472e-02, 2.2472e-02, 3.3708e-02, 3.3708e-02, 3.3708e-02, 3.3708e-02,\n",
            "        0.0000e+00, 4.7649e-03, 1.1236e-02, 2.2472e-02, 2.2472e-02, 2.2472e-02,\n",
            "        2.2472e-02, 3.3708e-02, 3.3708e-02, 4.4944e-02, 0.0000e+00, 1.7316e-01,\n",
            "        1.7393e-01, 1.7393e-01, 1.7393e-01, 1.7393e-01, 1.7393e-01, 1.7393e-01,\n",
            "        1.8751e-01, 1.9188e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3800e-03,\n",
            "        1.0989e-02, 2.1978e-02, 2.1978e-02, 2.1978e-02, 2.1978e-02, 2.1978e-02,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.4125e-02, 4.4125e-02, 4.4125e-02, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0989e-02, 1.0989e-02, 1.0989e-02, 2.1978e-02,\n",
            "        3.0116e-02, 6.5934e-02], device='cuda:0')\n",
            "tensor([0.0374, 0.0374, 0.0374, 0.0374, 0.0374, 0.0374, 0.0374, 0.0374, 0.0374,\n",
            "        0.0374, 0.0401, 0.0401, 0.0401, 0.0401, 0.0401, 0.0401, 0.0401, 0.0401,\n",
            "        0.0401, 0.0401, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217,\n",
            "        0.0217, 0.0217, 0.0217, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157, 0.0157,\n",
            "        0.0157, 0.0157, 0.0157, 0.0157, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
            "        0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0654, 0.0654, 0.0654,\n",
            "        0.0654, 0.0654, 0.0654, 0.0654, 0.0654, 0.0654, 0.0654, 0.1409, 0.1409,\n",
            "        0.1409, 0.1409, 0.1409, 0.1409, 0.1409, 0.1409, 0.1409, 0.1409, 0.0245,\n",
            "        0.0245, 0.0245, 0.0245, 0.0245, 0.0245, 0.0245, 0.0245, 0.0245, 0.0245,\n",
            "        0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240, 0.0240,\n",
            "        0.0240, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217,\n",
            "        0.0217, 0.0217, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326,\n",
            "        0.0326, 0.0326, 0.0326, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
            "        0.0108, 0.0108, 0.0108, 0.0108, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326,\n",
            "        0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0586, 0.0586, 0.0586, 0.0586,\n",
            "        0.0586, 0.0586, 0.0586, 0.0586, 0.0586, 0.0586, 0.0326, 0.0326, 0.0326,\n",
            "        0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.2198, 0.2198,\n",
            "        0.2198, 0.2198, 0.2198, 0.2198, 0.2198, 0.2198, 0.2198, 0.2198, 0.0288,\n",
            "        0.0288, 0.0288, 0.0288, 0.0288, 0.0288, 0.0288, 0.0288, 0.0288, 0.0288,\n",
            "        0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217,\n",
            "        0.0217, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326,\n",
            "        0.0326, 0.0326, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339, 0.0339,\n",
            "        0.0339, 0.0339, 0.0339, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
            "        0.0437, 0.0437, 0.0437, 0.0437, 0.0759, 0.0759, 0.0759, 0.0759, 0.0759,\n",
            "        0.0759, 0.0759, 0.0759, 0.0759, 0.0759, 0.0460, 0.0460, 0.0460, 0.0460,\n",
            "        0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0460, 0.0215, 0.0215, 0.0215,\n",
            "        0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0215, 0.0561, 0.0561,\n",
            "        0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0561, 0.0337,\n",
            "        0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337, 0.0337,\n",
            "        0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449, 0.0449,\n",
            "        0.0449, 0.1919, 0.1919, 0.1919, 0.1919, 0.1919, 0.1919, 0.1919, 0.1919,\n",
            "        0.1919, 0.1919, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220, 0.0220,\n",
            "        0.0220, 0.0220, 0.0220, 0.0441, 0.0441, 0.0441, 0.0441, 0.0441, 0.0441,\n",
            "        0.0441, 0.0441, 0.0441, 0.0441, 0.0659, 0.0659, 0.0659, 0.0659, 0.0659,\n",
            "        0.0659, 0.0659, 0.0659, 0.0659, 0.0659], device='cuda:0')\n",
            "tensor([[0.0000, 0.0012, 0.0012,  ..., 0.0311, 0.0177, 0.0069],\n",
            "        [0.0000, 0.0012, 0.0012,  ..., 0.0311, 0.0177, 0.0069],\n",
            "        [0.0000, 0.0012, 0.0012,  ..., 0.0311, 0.0177, 0.0069],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0624, 0.0109, 0.0191],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0624, 0.0109, 0.0191],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0624, 0.0109, 0.0191]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.703\n",
            "VF res: tensor([[-0.2245, -0.1134,  0.1469,  ..., -0.0522, -0.2656,  0.0097],\n",
            "        [-0.2245, -0.1134,  0.1469,  ..., -0.0522, -0.2656,  0.0097],\n",
            "        [-0.2245, -0.1134,  0.1469,  ..., -0.0522, -0.2656,  0.0097],\n",
            "        ...,\n",
            "        [-0.2835, -0.0813,  0.0234,  ..., -0.1140, -0.1757,  0.1730],\n",
            "        [-0.2242, -0.1140,  0.1470,  ..., -0.0517, -0.2657,  0.0093],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.704\n",
            "VF res: tensor([[-0.2245, -0.1136,  0.1470,  ..., -0.0521, -0.2657,  0.0095],\n",
            "        [-0.2245, -0.1136,  0.1470,  ..., -0.0521, -0.2657,  0.0095],\n",
            "        [-0.2245, -0.1136,  0.1470,  ..., -0.0521, -0.2657,  0.0095],\n",
            "        ...,\n",
            "        [-0.2832, -0.0817,  0.0235,  ..., -0.1142, -0.1757,  0.1730],\n",
            "        [-0.2242, -0.1142,  0.1470,  ..., -0.0515, -0.2658,  0.0092],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.704\n",
            "VF res: tensor([[-0.2245, -0.1136,  0.1470,  ..., -0.0521, -0.2658,  0.0095],\n",
            "        [-0.2245, -0.1137,  0.1470,  ..., -0.0521, -0.2658,  0.0095],\n",
            "        [-0.2245, -0.1137,  0.1470,  ..., -0.0521, -0.2658,  0.0095],\n",
            "        ...,\n",
            "        [-0.2831, -0.0819,  0.0235,  ..., -0.1143, -0.1757,  0.1730],\n",
            "        [-0.2242, -0.1142,  0.1470,  ..., -0.0515, -0.2658,  0.0091],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1140,  0.1470,  ..., -0.0518, -0.2660,  0.0091],\n",
            "        [-0.2243, -0.1140,  0.1470,  ..., -0.0517, -0.2660,  0.0091],\n",
            "        [-0.2243, -0.1140,  0.1470,  ..., -0.0517, -0.2660,  0.0091],\n",
            "        ...,\n",
            "        [-0.2825, -0.0828,  0.0237,  ..., -0.1148, -0.1757,  0.1730],\n",
            "        [-0.2240, -0.1145,  0.1469,  ..., -0.0511, -0.2660,  0.0088],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1140,  0.1470,  ..., -0.0517, -0.2660,  0.0091],\n",
            "        [-0.2243, -0.1140,  0.1470,  ..., -0.0517, -0.2660,  0.0091],\n",
            "        [-0.2243, -0.1140,  0.1470,  ..., -0.0517, -0.2660,  0.0091],\n",
            "        ...,\n",
            "        [-0.2823, -0.0830,  0.0238,  ..., -0.1149, -0.1757,  0.1730],\n",
            "        [-0.2240, -0.1146,  0.1469,  ..., -0.0511, -0.2660,  0.0088],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.705\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.706\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.706\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.706\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "VF Result norm: 10.706\n",
            "VF res: tensor([[-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2661,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        [-0.2243, -0.1141,  0.1470,  ..., -0.0516, -0.2660,  0.0090],\n",
            "        ...,\n",
            "        [-0.2822, -0.0832,  0.0238,  ..., -0.1150, -0.1757,  0.1730],\n",
            "        [-0.2239, -0.1147,  0.1469,  ..., -0.0510, -0.2660,  0.0087],\n",
            "        [-0.2832, -0.0832,  0.0234,  ..., -0.1152, -0.1754,  0.1732]],\n",
            "       device='cuda:0')\n",
            "ys: -2.5371382236480713---2.3106775283813477; False\n",
            "ts: 0.0---0.21978022158145905; False\n",
            "aggr emb: -2.53695011138916---2.3106744289398193; False\n",
            "POS: -2.53695011138916---2.3106744289398193; False\n",
            "pos_intensity_loss: 0.5801839828491211---1.4904446601867676; False\n",
            "------------------Loss: 404.2149658203125\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "vmap: It looks like you're either (1) calling .item() on a Tensor or (2) attempting to use a Tensor in some data-dependent control flow or (3) encountering this error in PyTorch internals. For (1): we don't support vmap over calling .item() on a Tensor, please try to rewrite what you're doing with other operations. For (2): If you're doing some control flow instead, we don't support that yet, please shout over at https://github.com/pytorch/functorch/issues/257 . For (3): please file an issue.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-4cbc4bdf3fd2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     def _clip_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mbackward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"backward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mclosure_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mclosure_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoggle_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    305\u001b[0m             )\n\u001b[1;32m    306\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/adjoints.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_ts, grad_ys, grad_stats, grad_status)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[0mt_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                     )\n\u001b[0;32m--> 410\u001b[0;31m                     solution = aug_solver.solve(\n\u001b[0m\u001b[1;32m    411\u001b[0m                         \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/adjoints.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, problem, term, dt0, args)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Compute an initial step size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mconvergence_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvergence_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         dt, controller_state, f0 = step_size_controller.init(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/step_size_controllers.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, term, problem, method_order, dt0, stats, args)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdt0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mdt_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             dt0, f0 = self._select_initial_step(\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/step_size_controllers.py\u001b[0m in \u001b[0;36m_select_initial_step\u001b[0;34m(self, term, t0, y0, direction, dt_max, convergence_order, stats, args)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0merror_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/adjoints.py\u001b[0m in \u001b[0;36mvf\u001b[0;34m(self, t, y, stats, args)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0madj_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munflatten_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp_vf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mflatten_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvjp_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/apis.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         return vmap_impl(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/vmap.py\u001b[0m in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# If chunk_size is not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     return _flat_vmap(\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/vmap.py\u001b[0m in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mflat_in_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         )\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/adjoints.py\u001b[0m in \u001b[0;36mvjp_single_sample\u001b[0;34m(t_i, y_i, adj_y_i, arg_i)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0mvjp_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0madj_y_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/eager_transforms.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(func, has_aux, *primals)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mshould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdepend\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0moutside\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mf\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_vjp_with_argnums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/vmap.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_saved_tensors_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/eager_transforms.py\u001b[0m in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mdiff_primals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_argnums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0mtree_map_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_create_differentiable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_primals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mprimals_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchode/adjoints.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(params, t_, y_)\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/functional_call.py\u001b[0m in \u001b[0;36mfunctional_call\u001b[0;34m(module, parameter_and_buffer_dicts, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     return nn.utils.stateless._functional_call(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mparameters_and_buffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/stateless.py\u001b[0m in \u001b[0;36m_functional_call\u001b[0;34m(module, parameters_and_buffers, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_and_buffers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtie_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     ):\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-5dbca513762d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, times, y_s)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, input_output_dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VF Result norm: {torch.sqrt((res ** 2).sum().sum()):.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VF res: {res}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: vmap: It looks like you're either (1) calling .item() on a Tensor or (2) attempting to use a Tensor in some data-dependent control flow or (3) encountering this error in PyTorch internals. For (1): we don't support vmap over calling .item() on a Tensor, please try to rewrite what you're doing with other operations. For (2): If you're doing some control flow instead, we don't support that yet, please shout over at https://github.com/pytorch/functorch/issues/257 . For (3): please file an issue."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model=tpp.cuda(), train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669,
          "referenced_widgets": [
            "1bc2a418a11e434baecd4674ebca8271",
            "632b836f5efe48c281f823b50c475163",
            "21c749a6fa7346c69ba17088d729f850",
            "e6d083ba837940139a9b8f1e266a9293",
            "929565c543cd4f5e98d55d7d6ccbf805",
            "efdda1605aba41a1954c97ad5ccde981",
            "34672816365c4a49a2c0dbfe6bb6db58",
            "45c45243f54549a3916de80e3182e577",
            "2a4ed993a61849d7ade71772405b4773",
            "04edbcce6ac640889efb18beba54aabe",
            "303ee53ed8004b46afabe289b340e0f3"
          ]
        },
        "id": "hlbifPmncwZQ",
        "outputId": "f5a6ff21-6495-4564-bbb4-f36ed5daf810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name            | Type            | Params | Mode \n",
            "------------------------------------------------------------\n",
            "0 | backbone        | Backbone_mean   | 0      | train\n",
            "1 | vf              | VectorField     | 2.2 K  | train\n",
            "2 | encoder         | CatEmbedding    | 160    | train\n",
            "3 | solver          | OptimizedModule | 2.2 K  | train\n",
            "4 | intensity_layer | Sequential      | 17     | train\n",
            "5 | type_layer      | Sequential      | 170    | train\n",
            "------------------------------------------------------------\n",
            "2.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "2.5 K     Total params\n",
            "0.010     Total estimated model params size (MB)\n",
            "25        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bc2a418a11e434baecd4674ebca8271"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported format string passed to Tensor.__format__",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-d4f89154e79f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     def _clip_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# unused hook - call anyway for backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_redirection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-4bcbac21e0f1>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;34m\"\"\"Run the training step of this model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-4bcbac21e0f1>\u001b[0m in \u001b[0;36mshared_step\u001b[0;34m(self, stage, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# print(f\"time:\\n{time}\\nmask:\\n{nonpadding_mask}\\nembedding:\\n{embedding}\\ntypes:\\n{types}\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         pos_int, pos_type, neg_int = self.forward(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-55-4bcbac21e0f1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, time, nonpadding_mask, embedding, types)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# intensity loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mpos_intensity_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensity_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pos_intensity_loss: {pos_intensity_loss:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# event type loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "a0x0XEy1C5Xv",
        "outputId": "514fcc12-8347-4741-d114-1388968b30fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'VectorField' object has no attribute '_metrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a84038728524>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'VectorField' object has no attribute '_metrics'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.logged_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qagLtv_OBx-3",
        "outputId": "4ad215dc-03da-4d2c-e2f7-9671bec8e3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_loss': tensor(nan),\n",
              " 'train_posint_loss': tensor(nan),\n",
              " 'train_postype_loss': tensor(nan),\n",
              " 'train_negint_loss': tensor(nan)}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Загрузка датасета Churn"
      ],
      "metadata": {
        "id": "M47qzWFHsJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from urllib.parse import urlencode\n",
        "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "public_key = 'https://disk.yandex.ru/i/qpmYnFRGE7mQPw'  # Сюда вписываете вашу ссылку https://disk.yandex.ru/i/qpmYnFRGE7mQPw\n",
        "# Получаем загрузочную ссылку\n",
        "final_url = base_url + urlencode(dict(public_key=public_key))\n",
        "response = requests.get(final_url)\n",
        "download_url = response.json()['href']\n",
        "# Загружаем файл и сохраняем его\n",
        "download_response = requests.get(download_url)\n",
        "with open('train_churn.csv', 'wb') as f:   # Здесь укажите нужный путь к файлу\n",
        "    f.write(download_response.content)"
      ],
      "metadata": {
        "id": "Q0LMml6MrmzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "churn_dataset = pd.read_csv(\"/content/train_churn.csv\")\n",
        "churn_dataset['PERIOD'] = pd.to_datetime(churn_dataset['PERIOD'])\n",
        "churn_dataset['TRDATETIME'] = pd.to_datetime(churn_dataset['TRDATETIME'].str.replace(r'^(\\d{2}[A-Z]{3}\\d{2}):', r'\\1 ', regex=True), format='%d%b%y %H:%M:%S')\n",
        "\n",
        "churn_dataset['trx_category'] = churn_dataset['trx_category'].astype(str)\n",
        "churn_dataset = churn_dataset.sort_values(by=['PERIOD', 'TRDATETIME'])\n",
        "churn_dataset = churn_dataset.dropna(axis=1)\n",
        "\n",
        "# enough transactions\n",
        "vc = churn_dataset['cl_id'].value_counts()\n",
        "valid_cl_ids = vc.index[vc > 100]\n",
        "\n",
        "churn_dataset = churn_dataset[churn_dataset['cl_id'].isin(valid_cl_ids)]\n",
        "churn_dataset = churn_dataset.drop(['PERIOD', 'currency', 'amount'], axis=1)\n",
        "\n",
        "\n",
        "churn_dataset = churn_dataset.reset_index(drop=True)\n",
        "display(churn_dataset.head(2))\n",
        "display(churn_dataset.tail(2))\n",
        "display(churn_dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVfRBpfKqw7w",
        "outputId": "9d97e858-7ccc-44d0-b5f3-aedbb38c14c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   cl_id   MCC          TRDATETIME trx_category  target_flag  target_sum\n",
              "0   1290  5411 2016-10-07 00:00:00          POS            1   321242.09\n",
              "1   1290  6011 2016-10-07 18:57:17   WD_ATM_ROS            1   321242.09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78b0c825-9efe-454a-a991-819b03391205\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cl_id</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TRDATETIME</th>\n",
              "      <th>trx_category</th>\n",
              "      <th>target_flag</th>\n",
              "      <th>target_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1290</td>\n",
              "      <td>5411</td>\n",
              "      <td>2016-10-07 00:00:00</td>\n",
              "      <td>POS</td>\n",
              "      <td>1</td>\n",
              "      <td>321242.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1290</td>\n",
              "      <td>6011</td>\n",
              "      <td>2016-10-07 18:57:17</td>\n",
              "      <td>WD_ATM_ROS</td>\n",
              "      <td>1</td>\n",
              "      <td>321242.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78b0c825-9efe-454a-a991-819b03391205')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-78b0c825-9efe-454a-a991-819b03391205 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-78b0c825-9efe-454a-a991-819b03391205');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-29986e34-2578-4590-8956-185fee1f1e68\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29986e34-2578-4590-8956-185fee1f1e68')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-29986e34-2578-4590-8956-185fee1f1e68 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(churn_dataset\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cl_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1290,\n        \"max\": 1290,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1290\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 424,\n        \"min\": 5411,\n        \"max\": 6011,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TRDATETIME\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2016-10-07 00:00:00\",\n        \"max\": \"2016-10-07 18:57:17\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2016-10-07 18:57:17\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trx_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"WD_ATM_ROS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 321242.09,\n        \"max\": 321242.09,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          321242.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        cl_id   MCC          TRDATETIME trx_category  target_flag  target_sum\n",
              "363714    791  6011 2018-04-02 15:06:41   WD_ATM_ROS            1    32714.44\n",
              "363715    851  6011 2018-04-02 19:07:05   WD_ATM_ROS            0        0.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5771a5c8-e3b4-4a03-9f5b-9c2cc77ea60b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cl_id</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TRDATETIME</th>\n",
              "      <th>trx_category</th>\n",
              "      <th>target_flag</th>\n",
              "      <th>target_sum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>363714</th>\n",
              "      <td>791</td>\n",
              "      <td>6011</td>\n",
              "      <td>2018-04-02 15:06:41</td>\n",
              "      <td>WD_ATM_ROS</td>\n",
              "      <td>1</td>\n",
              "      <td>32714.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363715</th>\n",
              "      <td>851</td>\n",
              "      <td>6011</td>\n",
              "      <td>2018-04-02 19:07:05</td>\n",
              "      <td>WD_ATM_ROS</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5771a5c8-e3b4-4a03-9f5b-9c2cc77ea60b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5771a5c8-e3b4-4a03-9f5b-9c2cc77ea60b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5771a5c8-e3b4-4a03-9f5b-9c2cc77ea60b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ff4c9708-eed3-4f9b-934a-5394267c3571\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff4c9708-eed3-4f9b-934a-5394267c3571')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ff4c9708-eed3-4f9b-934a-5394267c3571 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(churn_dataset\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"cl_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 791,\n        \"max\": 851,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          851,\n          791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6011,\n        \"max\": 6011,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TRDATETIME\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2018-04-02 15:06:41\",\n        \"max\": \"2018-04-02 19:07:05\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2018-04-02 19:07:05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trx_category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"WD_ATM_ROS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23132.602366720435,\n        \"min\": 0.0,\n        \"max\": 32714.44,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(363716, 6)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn_dataset['trx_category'].value_counts().index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mq1NZa_Z2wf",
        "outputId": "2050f527-5c36-4ab0-fddb-5f7ed7829ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['POS', 'DEPOSIT', 'WD_ATM_ROS', 'WD_ATM_PARTNER', 'C2C_IN',\n",
              "       'WD_ATM_OTHER', 'C2C_OUT', 'BACK_TRX', 'CAT', 'CASH_ADV'],\n",
              "      dtype='object', name='trx_category')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_trx_category = ['POS', 'DEPOSIT', 'WD_ATM_ROS', 'WD_ATM_PARTNER', 'C2C_IN',\n",
        "       'WD_ATM_OTHER', 'C2C_OUT', 'BACK_TRX', 'CAT', 'CASH_ADV']\n",
        "\n",
        "trx_category_to_id = dict()\n",
        "\n",
        "for i, val in enumerate(id_to_trx_category):\n",
        "    trx_category_to_id[val] = i"
      ],
      "metadata": {
        "id": "1L7uqyHdZ4lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "target_flag --- ушел/не ушел\n",
        "\n",
        "нормировать время на 0-1"
      ],
      "metadata": {
        "id": "bOEtdV927WUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_cl_ids[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lz5-Aa1x69B",
        "outputId": "ef04ba69-dd44-4be2-f707-969588d99fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([2143, 5373, 5630, 4564, 1261, 5398, 10, 5847, 757, 1839], dtype='int64', name='cl_id')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "для каждого клиента формируем последовательность транзакций типа (время, категория)"
      ],
      "metadata": {
        "id": "2mkt3AqTxrPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groupped = list(churn_dataset.groupby(by=['cl_id'])[['TRDATETIME', 'trx_category', 'target_flag']])"
      ],
      "metadata": {
        "id": "ASy1_9dJxxJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groupped[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BCHEpLParbA",
        "outputId": "07d666de-df57-4b52-b0a1-f380f35c4fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1,),\n",
              "        TRDATETIME trx_category  target_flag\n",
              " 265860 2017-07-19          POS            0\n",
              " 267344 2017-07-20          POS            0\n",
              " 270488 2017-07-22          POS            0\n",
              " 273085 2017-07-24          POS            0\n",
              " 274408 2017-07-25          POS            0\n",
              " ...           ...          ...          ...\n",
              " 347440 2017-10-16          POS            0\n",
              " 347684 2017-10-17          POS            0\n",
              " 347685 2017-10-17          POS            0\n",
              " 347916 2017-10-18          POS            0\n",
              " 348154 2017-10-19          POS            0\n",
              " \n",
              " [104 rows x 3 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "\n",
        "for i in range(len(groupped)):\n",
        "    client_id = groupped[i][0][0]\n",
        "    transactions_ordered_in_time = groupped[i][1]\n",
        "\n",
        "\n",
        "    target = transactions_ordered_in_time['target_flag'].values\n",
        "    assert len(set(target)) == 1\n",
        "\n",
        "    target = target[0]\n",
        "    times = transactions_ordered_in_time['TRDATETIME'].values\n",
        "    times = (times - times.min()) / np.timedelta64(1, 'D')\n",
        "    times = times / times.max()\n",
        "\n",
        "    dataset[i] = {\n",
        "        'time': times,\n",
        "        'type': np.array(list([trx_category_to_id[x] for x in transactions_ordered_in_time['trx_category'].values])),\n",
        "        'target': target\n",
        "    }"
      ],
      "metadata": {
        "id": "K3R5Du21y90S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['time']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrBIUC-VzlfI",
        "outputId": "12cb2f83-df95-476d-ee80-00e54838af46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.01086957, 0.0326087 , 0.05434783, 0.06521739,\n",
              "       0.07432116, 0.07608696, 0.07608696, 0.08695652, 0.09782609,\n",
              "       0.13043478, 0.15217391, 0.29347826, 0.35869565, 0.36956522,\n",
              "       0.36956522, 0.36956522, 0.45652174, 0.47826087, 0.47826087,\n",
              "       0.51086957, 0.51086957, 0.51086957, 0.51086957, 0.51086957,\n",
              "       0.5326087 , 0.54347826, 0.58695652, 0.59782609, 0.60869565,\n",
              "       0.60869565, 0.60869565, 0.61956522, 0.63043478, 0.64130435,\n",
              "       0.64130435, 0.64130435, 0.64130435, 0.64130435, 0.65217391,\n",
              "       0.65217391, 0.66304348, 0.66304348, 0.67391304, 0.68478261,\n",
              "       0.68478261, 0.69565217, 0.70652174, 0.70652174, 0.7173913 ,\n",
              "       0.73703905, 0.73704748, 0.73913043, 0.73913043, 0.75      ,\n",
              "       0.75      , 0.75      , 0.75      , 0.76086957, 0.76086957,\n",
              "       0.76086957, 0.77173913, 0.77173913, 0.77173913, 0.77173913,\n",
              "       0.77173913, 0.77173913, 0.77173913, 0.77173913, 0.7826087 ,\n",
              "       0.7826087 , 0.7826087 , 0.7826087 , 0.79347826, 0.79347826,\n",
              "       0.79347826, 0.79347826, 0.79347826, 0.79347826, 0.79347826,\n",
              "       0.80434783, 0.80434783, 0.81521739, 0.81521739, 0.81521739,\n",
              "       0.81521739, 0.82608696, 0.82608696, 0.82608696, 0.84782609,\n",
              "       0.88043478, 0.89130435, 0.90217391, 0.90217391, 0.90217391,\n",
              "       0.91304348, 0.92391304, 0.94565217, 0.9673913 , 0.9673913 ,\n",
              "       0.97826087, 0.97826087, 0.98913043, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. MDB dataset\n",
        "https://huggingface.co/datasets/ai-lab/MBD"
      ],
      "metadata": {
        "id": "U0ymQEgfxGGK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwnDx6wcxHmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JG44Z_9as5Wq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}